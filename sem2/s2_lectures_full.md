# ЛЕКЦИЯ 1

- Вычислительная сложность алгоритма
- Функции на последовательностях
- Индуктивные функции, универсальный алгоритм вычисления индуктивных функций
- Индуктивные расширения не индуктивных функций

## Вычислительная сложность алгоритма

Вычислительную сложность оценивают, во-первых, числом элементарных операций, необходимых для выполнения алгоритма. Под элементарными опрациями обычно понимают 4 арифметических действия +, -, *, /, операции сранения <, >, операцию копирования и т.п.

Во-вторых, вычислительная сложность определяется также необходимым для выполнения алгоритма объёмом памяти (выражаемым в байтах).

Обычно интерес передставляет зависимость вычислительной сложности алгоритма от "размера" задачи - некоторого параметра, от которого зависит сложность.

Например, если входные данные представлены массивом, то размер задачи есть длина массива.

Параметр задачи чаще всего обозначают буквой $n$.

Зависимость сложности алгоритма от параметра n выражают какой-либо функцией от этого параметра.

Обычно получить точную оценку сложности алгоритма затруднительно, или в этом нет необходимости. Как правило получают оценку сложности для "наихудшего случая", т.е. при наименее благоприятных исходных данных. Иногда также делают оценку в среднем по всем возможным входным данным.

В связи с этим часто при получении оценки сложности алгоритма в виде функциональной зависимости от параметра $n$ интересуются только тем, как ведет себя эта зависимость при больших $n$ ($n \rightarrow \infty)$

**Определение.** Говорят, что неотрицательная функция

$$f(n)=O(g(n)), \ \ n \rightarrow \infty$$

где $g(n)$ - некоторая другая неотрицательная функция, если существует такая положительная константа $C>0$, и такое натуральное число $n_0$, что

$$\forall n>n_0 \ \ \ f(n) <= C g(n)$$

Например, тот факт, что функция $f(n)$ является ограниченной, с помощью символики O-большое можно записать так: $f(n)=O(1)$.

Таким образом, то, что алгоритмическая сложность некоторого алгоритма оценивается для наихудшего случая как $O(g(n))$ означает, что число необходимых элементарных операций, или необходимый объем памяти, не превзойдет $C g(n)$.

При этом, если только это не ясно из контекста, всегда уточняют, идет ли речь о количестве операций или о объеме памяти.

## Примеры алгоритмов с оценкой их вычислительной сложности

Числовая последоватьельность $a_1, a_2, ..., a_n$  называется отсортированной по неубыванию, если

$$ a_1 <= a_2 <= ... <= a_n $$

### Алгоритм проверки, является ли заданная последовательность отсортированной по неубыванию

Ясно, что ответ может быть получен за однократный перебор в цикле всех элементов заданной последовательности. Поэтому вычислительная сложность данного алгоритма имеет оценку $O(n)$.

**Замечание.** В Julia имеется встроенная функция issorted, проверяющая, аяляется ли заданная последовательность отсортированной по невозрастанию, или - по неубыванию (в зависимости от значения именованного параметра rev; по умолчанию rev = false и, соответственно, проверяется отсортированность по не убыванию).

Причем имеется возможность передавать в эту функцию последовательности (итерируемые объекты), элементы которых сами состоят из элементов (например, кортежи, пары типа Pair, их которых состоят словари (Dict)), к которым можно обращаться с помощью индекса. Требуемое значение индекса по умолчанию равно 1, но может быть изменено заданием значения именованного параметра by. Значение этого параметра является функциональным. Например

```julia
  julia> issorted([(1, "b"), (2, "a")], by = x -> x[2])
  false

  julia> issorted([(1, "b"), (2, "a")], by = x -> x[2], rev=true)
  true
```

### Алгоритм "быстрого" поиска заданного значенния в отсортированной последовательности

Рассмотрим следующую задачу. Имеется отсортированная последовательность, представленная вектором A. Требуется проверить, содержит ли эта последовательность значение a.

Ясно, что задачу можно было бы решить просто последовательным перебором значений элементов последовательности. Однако, если учесть, что последовательность является отсортированной по неубыванию, то возможно реализовать алгоритм, вычисдительная сложность которого будет иметь оценку O(log(n)).

В самом деле, искомое значение можно сравнить с элементом последовательности из её середины. Если икомое значение окажется больше, то левую половину последовательности можно отбросить, в противном случае следует отбрасывать правую половину последовательности. В результате, если искомое значение содержится в массиве, то будет найден индекс соответствующего элемента массива, в противном случае такого индекса не существует.

**Замечание.** В языке Julia имеется встроенная функция searchsorted, реализующая быстрый поиск в массиве.

## Функции на последовательностях

Пусть задана последовательность объектов некторого типа:

$$ a_1, a_2, ..., a_n $$

где $a_k \in \Omega$  - некоторое множество (определяющее тип последовательности)

Будем использовать обозначения:

$$ A=[a_1,a_2,...,a_n]\in \Omega^n=\underbrace{\Omega\times...\times\Omega}_n $$

$$ \Omega^0={[\ ]} $$

где $[ \ ]$ - это пустая последовательность.

Также для множества всех последовательностей конечной длины (включая и пустую последовательность) будем использовать обозначение

$$ {\Sigma}=\bigcup_{n=0}^{\infty}{\Omega^n} $$

Тогда какую-либо функцию, определенную на всех последовательностях конечной длины с элементами из $\Omega$, со значениями в некотором множестве $U$ будем, как это принято в математике, обозначать:

$$ F:\Sigma\rightarrow U. $$

## Примеры функций на последовательностях и алгоритмы их вычисления

Длина последовательности:

$$ F(A)=length(A) \in \N \cup \{0\} $$

Вычисление этой функции сводится к вычислению n-го члена следующей вспомогательной последовательности:

$$ l_0=length([\ ])=0$$
$$ .... $$
$$ l_k=l_{k-1}+1 $$
$$ .... $$
$$ l_{n}=l_{n-1}+1 $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function length_(A)
    len = 0
    for _ in A
        len += 1
    end
    return len
end
```

**Замечание.** В языке Julia имеется встроенная функции length, однако она не вычисляется по этому алгоритму. Длина массива - это просто внутренний атрибут массивов Julia. Поэтому сложность встоенного алгоритма оценивается как O(1), а не - О(n), как в случае функции length_.

### Сумма членов последовательности

$$ F(A)=sum(A)=\sum_{k=1}^na_k\ \in U=\Omega $$

Вычисление этой функции сводится к вычислению n-го члена следующей вспомогательной последовательности: 

$$ s_0=sum([\ ])=0 $$
$$ .... $$
$$ s_{k}=s_{k-1}+a_k $$
$$ .... $$
$$ s_{n}=s_{n-1}+a_n $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function sum_(A)
    s = eltype(A)(0)
    for a in A
        s += a
    end
    return s
end
```

**Замечание 1.** В строке s = eltype(A)(0), по сути, переменной s присваиваивается просто значение нуля, но важно сразу определить, какого типа должен быть этот нуль. Встроенная функция eltype определяет тип элементов массива, получаемого в качестве аргумента.

Далее, поскольку значение типа - это, по существу, есть имя конструктора типа, то передав этому конструктору в качестве аргумента значение 0 (типа Int64), мы получим значение нуля нужного типа. Эта операция называется **явным преобразованием типа**. Явным - потому, что конструктор, осуществляющий такое преобразование вызывается явно.

Определение типа начального значения переменной s важно потому, что если этого не сделать, и присвоить, например, просто s=0, то, если в действительности в массиве A будут элементы другого типа, например, Float64, то после выполнения очередной операции сложения тип переменной s должен будет поменяться на Float64 (типизация в Julia динамическая). Этот эффект называется **нестабильностью типа**. Нестабильность типа не позволяет компилятору генерировать максимально производительный код, поэтому нестабильности типа, по возможности, следует избегать.

В рассматриваемом случае предотвратить нестабильность типа можно было бы сделать ещё и так:

```julia
function sum_(A::AbstractVector{T}) where T
    s = T(0)
    for a in A
        s += a
    end
    return s
end
```

где выражение where T в заголовке функции означает, что T - это формальный параметр, т.е. символическое имя, обозначающий некоторый тип. Этот тип будет определен (выведен динамическим компилятором) из значеия фаутического параметра, с которым будет вызвана функция sum_.

**Замечание 2.** В отличие от языков со стактической компиляцией, таких как C/C++, где типы данных существуют во время компиляции, а во время выполнения кода никаких типов данных уже нет. В языке Julia, в котором компиляция - динамическая, значение типа данных это такое же значение, как и значение любого другого типа, и поэтому может использоваться во время выполнения кода.

Строки s = eltype(A)(0) или, во втором случае, s = T(0) как раз и демонстрируют использование значения типа во время выполнения функции.

**Замечание 3.** В языке Julia имеется встроенная функция sum (однако встроенная функция sum является значительно более универсальной по сравнению с функцией sum_; см. help).

### Произведение членов последовательности

$$ F(A)=prod(A)=a_1 \cdot\ ... \cdot a_n=\prod_{k=1}^na_k\ \in U=\Omega $$

Вычисление этой функции сводится к вычислению n-го члена следующей вспомогательной последовательности:

$$ p_0=prod([\ ])=1 $$
$$ .... $$
$$ p_{k}=p_{k-1} \cdot a_k $$
$$ .... $$
$$ p_{n}=p_{n-1} \cdot a_n $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function prod_(A)
    p = eltype(A)(1)
    for a in A
        p *= a
    end
    return p
end
```

**Замечаеие 1.** В сторке p = eltype(A)(1) переменной p, по сути, присваивается значение 1. Однако во избежание нестабильности типа (см. пример выше) здесь осуществлено явное перобразование типа.

**Замечание 2.** В языке Julia имеется встроенная функция sum (однако встроенная функция sum является значительно более универсальной по сравнению с функцией prod_; см. help).

### Максимальное значение членов последовательности

$$ F(A)=maximun(A)=\max(a_1,...,a_n)\ \in U=\Omega $$

Вычисление этой функции сводится к вычислению n-го члена следующей вспомогательной последовательности:

$$ M_0=maximum([\ ])=-\infty $$
$$ .... $$
$$ M_{k}=\max(M_{k-1},a_k) $$
$$ .... $$
$$ M_{n}=\max(M_{n-1},a_n) $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function maximum_(A)
    M = typemin(eltype(A)) # m = -Inf
    for a in A
        M = max(M,a)
    end
    return M
end
```

**Замечание.** В языке Julia имеется встроенная функция maximum (однако встроенная функция maximum является значительно более универсальной по сравнению с функцией maximum_; см. help).

## Минимальное значение членов последовательности

$$ F(A)=minimun(A)=\min(a_1,...,a_n) \ \in U = \Omega. $$

Вычисление этой функции сводится к вычислению n-го члена следующей вспомогательной последовательности: 

$$ m_0=minimum([ \ ]) = \infty $$
$$ .... $$
$$ m_{k}=\min(m_{k-1},a_k) $$
$$ .... $$
$$ m_{n}=\min(m_{n-1},a_n) $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function maximum_(A)
    m = typemin(eltype(A)) # m = -Inf
    for a in A
        m = min(m,a)
    end
    return m
end
```

**Замечание.** В языке Julia имеется встроенная функция minimum; см. help.

### Индекс максимального значения членов последовательности

$$ F(A)=\argmax(A) $$

это значение индекса элемента, при котором элемент достигает наибольшего значения, т.е.

$$ maximum(A)=A[\argmax(A)] $$

Вычисление этой функции сводится к вычислению следующей вспомогательной последовательности:

$$ i_{max \ 1}=maximum([a_1])=1 $$
$$ ... $$
$$ i_{max\ k}=A[k]>A[k-1]\ ?\ k : i_{max \ k-1} $$
$$ ... $$
$$ i_{max \ n}=A[n]>A[n-1]\ ?\ n : i_{max \ n-1} $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function argmax_(A)
    @assert !isempty(A)
    imax = firstindex(A)
    for k in eachindex(A)
        if A[k] > A[imax] 
            imax = k
        end
    end
    return imax
end
```

**Замечание 2.** В языке Julia имеется встроенная функция argmax (однако эта функция является значительно более универсальной по сравнению с функцией argmax_). Имеется также и аналогичная встроенная функция argmin(A); см. help.

## Значение многочлена в точке, вычисленное по последовательности его коэффициентов, заданной по убыванию степеней, по хеме Горнера

$$ P_n(x)=a_0 \cdot x^n + a_1 \cdot x^{n-1} + ... + a_{n-1} \cdot x + a_n $$

Будем считать, что задан массив коэффициентов $A=[a_0,a_1,...a_n]$, и некторое значение аргумента $x$. Тогда $F(A)=P_n(x).$

Для вычисления этой функции воспользуемся следующей вспомогательной последовательностью многочленов:

$$ Q_0(x)=a_0 $$
$$ Q_1(x)=Q_0 \cdot x + a_1 = a_0 \cdot x + a_1 $$
$$ .... $$
$$ Q_k(x)=Q_{k-1} \cdot x + a_k $$
$$ .... $$
$$ Q_n(x) = Q_{n-1} \cdot x + a_n = P_n(x) $$

Соответствующий программный код на языке Julia выглядит так:

```julia
function evalpoly_(x,A)
    Q = first(A) # - это есть a_0
    for a in @view A[2:end]
        Q=Q*x+a
    end
    return Q
end
```

**Замечание.** В языке Julia имеется встроенная функция evalpoly, реализующая данный агоритм; см. help. Кроме того, для работы с многочленами в языке Julia имеется также специальный пакет Polynomials.jl (см. https://github.com/JuliaMath/Polynomials.jl)

## Индуктивные функции на последовательностях

Зададимся вопросом: что общего у всех рассмотреннных выше функций на последовательностях? Чтобы ответить на этот вопрос с математической точностью, понадобится следующее определение.

**Определение.** Функция $F:\Sigma\rightarrow U$ называется индуктивной (по А.Г.Кушниренко), если существует такая функция двух переменных (операция) $op: U \times \Omega \rightarrow U$, такая, что для любой последовательности A $\in \Sigma$ и для любого нового элемента a $\in \Omega$,

$$ F([A...,a])=op(F(A),a), $$

где [A..., a] = [A[1], ..., A[end], a]

Как можно убедиться все рассмотренные выше функции являются индуктивными.

Так, в случае F(A)=length(A), op(L,a)=L+1 (зависимость от второго аргумента здесь только формальная);

- в случае F(A)=sum(A), op(s, a) = s+a;

- в случае F(A)=prod(A), op(p, a) = p*a;

- в случае F(A)=maximum(A), op(M, a) = max(M, a);

- в случае F(A)=minimum(A), op(m, a) = min(m, a);

- в случае F(A)=argmax(A), op(imax, A[k]) = A[k] > A[imax] ? k : imax;

- в случае F(A)=$P_n(x)$, op(Q, a) = Q*x + a;

наконец, в случае F(A) = insertsort!(A), op(A[1:k], A[k+1]) = end_insert!(A[1:k+1]).

Можно заметить, что вычисление любой индуктивной функции можно свести к следующей универсальной схеме (алгоритму), точнее говоря, рассматриваемая ниже схема может иметь незначительные вариации, связанные с инициализацией переменной, в которой затем формируется результат вычислений:

```julia
y = F([]) # значение индуктивной функции на пустой последовательности 
for a in A
    y = op(y,a)
end
```

Здесь под $A$ понимается некоторый итерируемый объект, представляющий последовательность. Не обязательно это именно массив, это также может быть и кортеж, и диапазон, и генератор, и какой-либо контейнер, например, множество.

При этом функцию F(A) необходимо доопределять на пустой последовательности таким значением, нейтральным по отношению к опрерации op.

Например, при вычислении суммы чисел, таким нейтральным значением будет число 0, при вычислении произведения чисел, нейтральным значением будет число 1, при поиске минимального элемента, нейтральным значением будет символ бесконечности, при сортировке массива (вставками) - пустой массив.

Но иногда удобнее обходиться без доопределения вычисляемой функции на пустой последовательности, тогда алгоритм примет вид:

```julia
y = F([A[1]]) # значение индуктивной функции на подпоследовательности, содержащей только первый элемент A
for a in A[2:end]
    y = op(y,a)
end
```

Вообще, начинать вычисления можно не только с пустой последовательности, или с последовательности из одного элемента, но и - с последовательности, содержащей любое другое число начальных элементов.

При программировании вычислений индуктивной функции требуется рассматривать входные данные как последовательность некоторых значений, в требуемом порядке поступающих для "обработки".

**Замечаие.** Если функция на последовательности является индуктивной, то в нашем распоряжении имеется рассмотренный здесь универсальный алгоритм ее вычисления. Для записи этого алгоритма требуется только инициализачия начального значения переменной y (в нашей записи) и конкретизация операции op, т.е. определение соответствующей функции 2-х переменных.

## Встроенная функция reduce

Для вычисления любой индуктивной функцийив языке Julia есть универсальная reduce, являющаяся функцией высшего порядка (в языке Python также имеется подобная функция, с тем же именем):

```julia
reduce(op, itr; [init])
```

где

op - это аргумент типа Funсtion, определяющий рекурсивную опрерацию, т.е. соответствующую функцию 2-х аргументов;
itr - это итерируемый объект, задающий последовательность (например, одномерный массив);
init - необязательный именованный аргумент (квадратные скобки обозначают, как это принято в прграммировании, что параметр необязательный), определяет значение, которым доопределяется вычисляемая индуктивная функция на пустой последовательности. При отсутствии этого аргумента, вычисление будет осуществляться в соответствии со вторым вариантом универсального алгоритма.

Например, функция sum, могла бы быть определена следующим образом:

```julia
sum_(A)=reduce(+, A; init=eltype(A)(0))
```

В этом случае sum([]) вернет 0.0 (тип результата будет именно Float64, потому что аргумент eltype([]) имеет значение Float64).

А если определить функция sum так:

```julia
sum_(A)=reduce(+, A)
```

то вызов sum([]) приведет к ошибке (функция не определена на пустой последовательности).

Точно также, в одну сточку, можно было бы реализовать и рассмотренную ранее функцию eval_poly(x,A), вычисляющую значение многочлена в точке по схеме Горнера:

```julia
evalpoly_(x,A)=reduce((Q,a)->Q*x+a, A)
```

## Сортировка числового массива вставками

Задача сортировки массива A состоит в том, чтобы переставить его элементы так, чтобы получилось: A[1] <= A[2] <=...<= A[end].

Существует множество популярных алгоритмов сортировки, разной алгоритмической сложности. Но далеко не все из них можно рассматривать как вычисление индуктивной функции на последовательности. Однако есть одно исключение - это так называемый алгоритм сортирвки вставками.  

Идея сортировки вставками состоит в том, что если первые k элементов массива A уже отсортированы, то для того, чтобы получить отсортированными первые k+1 элементов этого массива, достаточно просто вставить eго k+1-ый элемент в соответствующую позицию, сдвигая поочередно все элементы, которые больше его, на 1 позицию вправо. Поскольку для k=1 необходимое предположение об отсортированности начальной части массива всегда выполнено, то остается только проитерировать k от 2 до n (n=length(A).)

Сортировка массива A, в этом случае F(A) = sort(A) $\in \Sigma$ - есть индуктивная функция.

Соответствующая функция на языке Julia могла бы выглядеть так:

```julia
function insertsort!(A)
    n=length(A)
    for k in eachindex(A) #2:n
        # часть массива A[1:k-1] уже отсортирована
        op_insert!(A,k)
    end
    return A
end

op_insert!(A,k) =
    while k>1 && A[k-1] > A[k]
        A[k-1], A[k] = A[k], A[k-1]
        k -= 1
    end
```

Сложность алгортма сортировки вставками оценивается как $O(n^2)$.

**Вопрос:** можно ли добиться оценки сложности сортировки массива вставками, если вставку осуществлять на основе алгоритма быстрого поиска?

**Ответ:** нет нельзя. (Почему?)

## Однопроходные алгоритмы

Под однопроходым алгоритмом понимаются алгорим, который выдаёт ответ в результате однократного перебора элементов некоторой последовательности, представляющей исходные данные. Сложность всех однопроходных  алгоритмов может быть оценена как O(n), где n - это длина последлвательности.

В этом смысле универсальная схема вычисления индуктивной функции на последовательности всегда даёт однопроходный алгоритм, но только при условии, что выполняемая на каждом шаге такого алгоритма операция (op) имеет асимптотическую оценку сложности - $O(1)$.

Например, все рассмотренные выше алгоритмы вычисления индуктивных функций, за исключением сортировки вставками, являются однопроходными.

Сортировка вставками не является однопроходным алгоритмом. Сложность операции вставки в алгоритме сортировки вставками оценивается только как $O(n)$ (даже если применить алгоритм быстрого поиска; имеется ввиду, что последовательность представлена массивом, см. выше).

## Индуктивные расширения неиндуктивных функций

Пусть

$$ F(A)=mean(A)=sum(A)/length(A) $$

Эта функция не является индуктивной. Доказать это можно, разсуждая от противного. В самом деле, предположим, согласно определению индуктивной функции, что существует такая функция двух переменных $op(m, a)$, такая, что для любых $A \in \Sigma$ и $a \in \Omega$,

$$ mean([A[1],...,A[end], a])=op(mean(A),a) $$

Тогда это означало бы, что величины $mean(A)$ и $a$ однозначно определяют результат.

С другой стороны,

$$ mean([A[1],...,A[end], a])=\frac{sum(A)+a}{length(A)+1}=\frac{mean(A)+\frac{a}{length(A)}}{1+\frac{1}{length(A)}} $$

Отсюда видно, что значения $mean(A)$ и $a$ сами по себе не определяют величину $mean([A...,a])$, т.к. тут имеется еще зависимость от $length(A)$, причем между $mean(A)$ и $length(A)$, очевидно, нет взаимно однозначного соответствия. Таким образом, приходим к противоречию.

Однако, функции $sum(A)$ и $length(A)$, как мы знаем, сами по себе являются индуктивными. Поэтому, функция на последовательностях, значениями которой будет пара значений (кортеж значений):

$$ F^*(A)=(sum(A), length(A)) $$

уже будет индуктивной.

Эту индуктивную функцию можно вычислить с использование универсального алгоритма, а интересующая нас не индуктивная функция $mean(A)$ уже просто выражается через ее компоненты.

**Определение.** Функция

$$ F^*: \Sigma \rightarrow U^* $$

называется индуктивным расширение не индуктивной функции $F(A)$, если существует функция

$$ P: U^* \rightarrow U $$

такая, что для любой последовательности $А \in \Sigma$

$$ F(A)=P(F^*(A)) $$

В частности, в случае не индуктивной функции $mean(A)$ её индуктивным расширением будет функция

$$ F^*(A)=(sum(A),length(A)) $$

При этом

$$ mean(A)=\frac{sum(A)}{length(A)}=\frac{F^*(A)[1]}{F^*(A)[2]} $$

### Примеры построения индуктивных расширений неиндуктивный функций

**Пример 1.** Функция mean(A), вычисляющая среднее арифметической последовательности, он уже был рассмотрен.

**Пример 2**. Наибольшее значение в заданной последовательности может быть не единственным (может существовать несколько членов последовательности, иеющих максимальное значение).

Пусть требуется посчитать число максимальных элементов в заданной последовательности. Число максимальных элементов, очевидно, не является индуктивной функцией на последовательностях.

В самом деле, если известно число максимальных элементов в некоторой начальной части заданной последовательности, и получено значение еще одного, следующего, члена последовательности, то не известно, как правильно должно изменится общее число максимумов - это зависит от значения самого максимума: либо новый член последовательности меньше максимума, тогда число максимумов останется прежним, либо он равен прежнему максимуму, и тогда общее число максимумов надо увеличить на 1, либо его значение больше прежнего максимума, и тогда число максимумов должно быть положено равным 1.

Таким образом, ясно, что индуктивным расширением, в данном случае, будет кортеж из двух значений: число максимумов и само максимальное значение.

**Пример 3.** Вычисление значения многочлена и его производной в точке, по заданной последовательности его коэффициентов, по схеме Горнера.

Пусть некоторый многочлен задан последовательностью своих коэффициентв, с ледующих в порядке убывания степеней, т.е.  пусть $a_0$ - это коэффициент при степени $n$ (старшая степень), $a_1$ - коэффициент при степени $n-1$ и т.д. Требуется вычислить значение значение **производной** этого многочлена в заданной точке $x$, причем используя для этого минимально возможное число арифметических операций.

Ясно, что если задачу рассматривать как вычисление функции на последовательности $a_0, a_1,..., a_n$, то, в отличие от значения самого многочлена, вычисляемого по схеме Горнера, значение его производной не является индуктивной функцией.

В самом деле, пусть

$$ P_n(x) = a_0 x^n + a_1 x^{n-1} + ... + a_n $$

Как и в схеме Горнера рассмотрим вспомогательную последовательность многочленров $Q_k(x), k = 0,1,2,...,n$:

$$ Q_0(x) = a_0 $$

$$ Q_1(x) = a_0 x + a_1 $$

...

$$ Q_{k+1}(x) = Q_k(x)x + a_{k+1} $$

...

$$ Q_n(x) = P_n(x) $$

Ясно, что если при некотором $k$ известно значение  $Q'_k(x)$, то получив дополнительно ещё только очередное значение $a_{k+1}$ невозможно будет однозначно определить значение $Q'_{k+1}(x)$ (потребуется ещё значение самого многочлена $Q_k(x)$).

Действительно, дифференцируя выражение

$$ Q_{k+1}(x) = Q_{k}(x)x + a_{k+1} $$

где $k=0,1,2,...$, получим

$$ Q'_{k+1}(x) = Q'_k(x)x + Q_k(x) $$

Откуда видно, что для вычисления Q'_{k+1}(x) требуются сразу обе эти рекуррентные формулы $($т.к. $Q_k(x)$ не может быть однозначно выражено через $Q'_k(x))$, с начальными условиями

$$Q_0(x)=a_0, \ \ Q'_0(x) = 0$$

Таким образом, полученные рекуррентные формулы определяют индуктивное расширение

$$ F^*(a_0,...,a_k) = (Q_k(x); Q'_k(x)) $$

не индуктивной функции

$$ F(a_0,...,a_k) = Q'_k(x) $$

**Пример 4.** Вычисление наибольшего значения суммы непрерывного сегмента числовой последовательности.

Пусть имеется числовая последовательность $a_1, a_2,..., a_n$.

Требуется найти однопроходный алгоритм вычисления величины

$$ M_n = \max_{i,j} \sum_{m=i}^{j} a_m $$

где максимум ищется по всем парам индексов $i,j$, таким, что $0<=i<=j<=n$.

Если бы последовательность содержала только неотрицательные числа, то задача свелась бы к простому суммированию всей последовательности, полагая $i=1, j=n$.

Однако если среди членов последовательности имеются и положительные, и отрицательные, то возникает проблема выбора оптимальных значений $i$ и $j$.  

Как и во всех случаях, когда требуется получить однопроходный алгоритм, необходимо понять, какую информацию, полученную на $k$-ом шаге алгоритма надо сохранять (в соответствующих переменных), чтобы на следующем шаге иметь возможность выдать ответ уже для последовательности $a_1, a_2,..., a_k, a_{k+1}$.

Обозначим через $M_k$ - интересующее нас значение для последовательности $a_1, a_2,..., a_k$.

Введем дополнительную величину
$$M^*_k = \max_i \sum_{m=i}^{k} a_m $$

где максимум ищется только по нижнему пределу $i$ индекса суммирования $m$, при фиксированом его верхнем пределе, равном $k$.

Тогда, очевидно, имеем

$$ M^*_{k+1} = max\{M^*_k+a_{k+1}, \ a_{k+1}\}$$

$$ M_{k+1}=max\{M^*_{k+1}, M_k\} $$

Таким образом, имеем индуктивное расширение

$$F^*(a_1,...,a_k) = (M^*_k; M_k)$$

неиндуктивной функции

$$F(a_1,...,a_k) = M_k$$

# Ллукция 2

## Однопроходные алгоритмы (прдолжение)

Рассмотрим задачу вычисления **квадрата среднеквадратического отклонения (СКО)** последовательности числовых данных.

Пусть дана числовая последовательность $a_1, a_2, ..., a_N$.

Требуется за один проход вычислить **квадрат среднеквадратического отклонения от среднего значения** этой последовательности.

Среднее значение последовательности - это есть среднее арифметическое всех ее членов:

$$ M = \frac{1}{N} \sum_{i=1}^{N} a_i $$

Квадрат **среднеквадратического отклонения** от среднего значения - это среднее арифметическое кваратов всех от всех отклонений от среднего значения:

$$ D = \frac{1}{N} \sum_{i=1}^{N} (a_i-M)^2 $$

Может показаться, на первый взгляд, что решить эту задачу за один проход не получится. В самом деле, казалось бы, что сначала, за один проход, будет необходимо вычислить величину $M$, а затем уже, за второй проход, вычислять $D$, непосредственно по имеющейся формуле. Однако оказывается, что для не индуктивной функции $D=D(a_1,...,a_N)$ имеется индуктивное расширение, которое позволит вычислить эту функцию всего за один проход. 

В самом деле
$$ D = \frac{1}{N} \sum_{i=1}^{N} (a_i-M)^2 = $$
$$ =\frac{1}{N} \sum_{i=1}^{N} (a_i^2-2a_iM+M^2) = $$
$$ =\frac{1}{N} \sum_{i=1}^{N} (a_i^2-2a_iM+M^2) = $$
$$ =\frac{1}{N} \sum_{i=1}^{N} a_i^2 - 2M\frac{1}{N}\sum_{i=1}^{N} a_i + M^2 = \frac{1}{N} \sum_{i=1}^{N} a_i^2 - M^2 $$
$$ D= \frac{1}{N} \sum_{i=1}^{N} a_i^2 - \Big( \frac{1}{N} \sum_{i=1}^{N} a_i \Big)^2 $$

Или, в окончательном виде,
$$ D= \frac{1}{N} S^{(2)}_N - \Big( \frac{1}{N} S^{(1)}_N \Big)^2 $$

где 

$$ S^{(2)}_N=\sum_{i=1}^{N} a_i^2 $$

$$ S^{(1)}_N=\sum_{i=1}^{N} a_i $$

Поскольку величины $N, S^{1}_N, S^{(2)}_N$, рассматриваемые как функции от последовательности, $A[1],A[2], ...,A[N]$ являются индуктивными, то кортеж их значений $\big(N, S^{1}_N, S^{(2)}_N \big)$ есть искомое индуктивное расширение функции $D$ (определенной на последовательностях).

Полученное индуктивное расширение важно с практической точки зрения тем, что, во первых, массив может быть очень длинным, и тогда экономия на его повторном проходе может оказаться весьма существенной. Во-вторых, это также дает возможность распространить данную задачу на случай, когда величина $N$ не считается фиксированной, а неограниченно возрастает: $N=1,2,3,...$ (рассматривается непрерывный поторк данных). В таком случае величины оценок и среднего значения $M=M_N$, и дисперсии $D=D_N$ будут считаться "текущими", т.е. зависящими от очередного $N$. Тогда наблюдая за значениями этих величин, можно будет, например, сделать вывод о "стационарности" потока данных, если эти величины почти не изменяются, или, в противном случае, - о отсутствии "стационарности" потока данных.

**Замечание.** В статистике величину $D$ называют оценкой **дисперсии** данных. А квадратный корень из этой величины называется оценкой **среднего квадратического отклонения** (СКО). СКО обычно обозначается символом $\sigma = \sqrt{(D)}$. Эта величина характеризует средний разброс отклонений значений последовательности от величины $M$.

В пакете `Statistics.jl` имеется функция `std`, вычисляющая оценку величины среднего квадратического отклонения.

Кроме того, в статистике величину $D$ часто определяют так же несколько по другой формуле:

$$ D = \frac{1}{N-1} \sum_{i=1}^{N} (a_i-M)^2 $$

Это так называемая **не смещенная оценка**, в отличие от **смещенной оценки** величины среднеквадратического отклонения, введенной ранее. Смысл этих понятий определяется в курсе математической статистики, которую  студенты-матаматики изучают на 3-ем курсе.

Но при больших $N$ отличия между этими двумя формулами будут малозначителыми.

## Быстрая сортировка Хоара

Ранее были расммотрены некоторые алгоритмы сортировки квадратичной сложности.

Существуют однако алгоритмы сортировки сложности $O(n*log(n))$. При этом можно доказать, что в общем случае, когда сортировка предполагает преремещения элементов (т.е. если речь не идет о сортировке подсчетом), то получить лучшую асимптотику не возможно.

Рассмотрим один из таких алгоритмов, который называется алгоритмом быстрой сортировки, или алгоритмом Хоара. Это один из самых эффективных и популярных алгоритмов сортировки.

В основе быстрой сортировки лежит следующая вспомогательная процедура частичной сортировки.

Пусть имеется массив $A$ и значение одного из его элементов, равное $b$. Требуется переставить элементы в массиве $A$ так, чтобы в нем сначала следовали все элементы, меньшие $b$, затем - все, равные $b$, а затем - все, большие $b$.

Причем алгоритмическая сложность этой процедуры должна оцениваться как $O(N)$, где $N=length(A)$, и дополнительные массивы.

Решим эту задачу с использованием метода инварианта цикла.

Напомним, что инвариантом цикла (с предусловием) называют утверждение (предикат), зависящее от фазовых переменных цикла (т.е. переменнных, которые могут изменяться в теле цикла), имеющее значение "истина" как до начала цикла, так и после любого числа его повторений.

Идея метода состоит в том, что для решения задачи сначала надо сформулировать подходящий инвариант цикла, а затем уже сконструировать соответствующий цикл.

Пусть величины $K, M, L$ (индексы массива $A$) такие, что

- $\forall i \in 1:K \ \ \ A[i]<b$
- $\forall i \in K+1:L \ \ \ A[i]==b$
- $\forall i \in M+1:N \ \ \ A[i]>b$

Эти три пункта, выполняемые одновременно, и будут составлять утверждение требуемого инварианта цикла. При этом в инварианте цикла ничего не утверждается про элементы массива для диапазона индексов $L+1:M$, этот диапазон индексов будет соответствовать еще не "обработаной" части массива. При чем в самом начале рассматриваемой процедуры частичной сортировки весь массив должен совпадать с этой "не обработанной" частью, а в конце процедуры "необработанная" часть должна будет получиться пустой.

Таким образом, искомая процедура частичной сортировки сводится к следующему циклу:

```julia
N = length(A)
K=0
L=0
M=N
#ИНВАРИАНТ: A[1:K] < b && A[K+1:L] == b && A[M+1:N] > b
while L < M 
    if A[L+1] == b
        L += 1
    elseif A[L+1] > b
        A[L+1], A[M] = A[M], A[L+1]
        M -= 1
    else # if A[L+1] < b
        L += 1; K += 1
        A[L], A[K] = A[K], A[L]
    end
end
```

Теперь с использованием этой вспомогательной процедуры массив может быть отсортирован рекурсивно следующим образом.

```julia
function quick_sort!(A)
    if isempty(A)
        return A
    end
    N = length(A)
    K, M = part_sort!(A, rand(1:N)) # - "базовый" элемент массива выбирается случайнам образом
    quick_sort!(A[1:K])
    quick_sort!(A[M:N])
    return A
end

function part_sort!(A, b)
    N = length(A)
    K=0
    L=0
    M=N
    #ИНВАРИАНТ: A[1:K] < b && A[K+1:L] == b && A[M+1:N] > b
    while L < M 
        if A[L+1] == b
            L += 1
        elseif A[L+1] > b
            A[L+1], A[M] = A[M], A[L+1]
            M -= 1
        else # if A[L+1] < b
            L += 1; K += 1
            A[L], A[K] = A[K], A[L]
        end
    end
    return K, M+1 
    # 1:K и M+1:N - эти диапазоны индексов определяют ещё не 
    # отсортированные части массива A
end
```

Оценить сложность алгоритма быстрой сортироваки quick_sort! можно следующим образом. Поскольку каждый раз перед процедурой частичной сортировки part_sort! "базовый" элемент $b$ массива A выбирается случайным образом, то можно считать, что **в среднем** размеры его частей $A[1:K] и A[M+1:N]$, подлежащих дальнейшей сортировке, но уже по отдельности, будут получаться приблизительно равными.

Для упрощения анализа условимся считать их равными $N/2$. Тогда всю процедуру сортировки можно будет представить двоичным деревом высоты $log_2(N)$ (каждый узел этого дерева фиксирует факт разделения рекурсивно сортируемой части массива на два подмассива равной длины). При этом корню этого дерева соответствует $N$ операций сранения, и каждому его последующему ярусу тоже сооттветствуют те же $N$ операций сравнения.

Таким образом, потребуется всего $N\log_2N$ операций, т.е. оценка сложности алгоритма сортировки в среднестатистическом смысле может быть выражена как $O(N\log(N))$.

## Порядковые статистики, алгоритм быстрого вычисления порядковых статистик

Пусть имеется числовой массив $А$. Его $k$-ой **порядковой статистикой** называется значение $k$-го элемента этого массива, которое получилось бы после реализации процедуры сортировки массива $A$.

Однако для вычисления $k$-ой порядковой статистики ($k$ считается фиксированным) вовсе не обязательно сортировать массив. Существует алгоритм вычисления этой величины, имеющий сложность всего $O(N)$, т.е. быстрый алгоритм.

В самом деле, если индекс $k$ задан, то требуемую процедуру вычисдения $k$-ой порядковой статистики легко получить из рассмотренного выше алгоритма Хоара быстрой сортировки. В самом деле, вычисление $k$-ой порядковой статистики от процедуры сортировки Хоара будет отличаться лишь тем, что для последующей после частичной сортирвки массива дальнейшая обработка массива должна бутет производиться лишь только над одной из двух полученных его частей, а именно, той из них, диапазон индексов которой включает заданное $k$.

В результате, первая частичная сортирвка даст $O(N)$ операций сравнения, вторая - $O(N/2)$, третья - $O(N/4)$ и т.д., что в сумме составит всего $O(N)$ операций.

**Замечание.** Минимальное и максмальное значения массива явяются его 1-ой и $N$-ой порядковыми статистиками, соответственно. Однако, хотя сложность их вычисления также оценивается как $O(N)$, их вычисление обычным способом потребует вдвое меньше сравнений (не говоря уже о том, что оно вовсе не потребует престановок элементов массива, что существенно более затратно по сравнению с просто опереацией сравнения).

## Медиана массива

Если длина $N$ массива нечетная, то его медианой называется порядковая статистика с индексом $(N-1)/2$. В случае же четной длины массива его медианой можно считать среднее арифметическое двух порядковых статистик с индексами $N/2-1$ и $N/2+1$.

Поэтому алгоритм вычисления медианы массива также может основываться на быстром алгоритме вычисления порядковых статистик.

Медиана массива, наряду со средним (средним арифметическим) значением массива является важной статистической характеристикой содержащихся в нем данных. Например, эта характеристика более адекватно оценивает уровень доходов большинства граждан, нежели простое среднее арифметическое значение уровня доходов всех граждан.

## Алгоритмы сортировки Шелла и "расчесыванием"

Рассмотренный здесь алгорим быстрой сортирвки Хоара является одним из наиболее эффективных и популярных алгоритмов сортировки.

Однако рассматривавшиеся ранее алгоритмы сортировки методом "пузырька" и вставками, имеющими квадрадратичную асимптотическую оценку сложности, также могут быть существенно улучшены. При этом эффективность таких улучшенных алгоритмов может оказаться сравнимой с эффективностью алгоритма Хоара.

Основная проблема алгоритма пузырьковой сортировки и алгоритма вставками состоит не в том, что они требуют $O(N^2)$ операций сравнения, а в том, что для их реализации может потребоваться столько же перестановок соседних элементов массива, т.к. перестановки элементов значительно более затратная процедура по сравнению с операцией сравнения.

Поэтому, если каким либо образом удастся уменьшить количество таких перстановок, то это очень существенно сократит время всей сортировки.

Зададимся вопросом, когда при выполнении указанных сортировок требуется наибольшее количество перестановок. Ответ, очевидно, будет следующим, - если в начале исходного массива было много "больших" чисел, потому, что тогда эти числа придется многократно обменивать с соедними до тех пор, пока они не окажутся на своих местах ближе к концу массива.

Число таких обменов можно попытаться уменьшить, если вначале сравнивать и, при нобходимости, менять местами не соседние  элементы масива, а только отстоящие друг от друга на значительно большее расстояние. Затем это расстояние надо будет уменьшить и повторить ту же процедуру частичной сортировки массива с самого его начала. Постепенно меньшать расстояние между сравниваемыми элементами, и повторять процедуру частичной сортировки надо до тех пор, пока это расстояние не станет равным 1, т.е. пока, наконец, не начнут сравниваться соседние элементы массива.

Это общая идея повышения эффетивности рассмотренных ранее алгоритмов сортирвки квадратичной сложности. При этом в обоих случаях первоначальное расстояние между сравниваемыми элементами массива перется равным длине массива (т.е. в начале сравниваются только первый и последний элементы массива).

В случае классической сортировки Шелла, базирующейся на сортировке вставками, в классическом её вариантк, это расстояние каждый раз уменьшается вдвое (приблизительно). При достижении расстояния между элементами равным 1 и после последнего выполнеиия сотрировки вставками уже всего массива, массив, очевидно, окажется отсортированным. Однако количество потребовавшихся при этом перестановок соседних элементов массива будет уже относительно небольшим, так все самые большие элементы ранее уже оказались перемещенными ближе к концу массива.

В случае же сортировки "расчесыванием", базирующейся на "пузырьковой" сортировке, это расстояние каждый раз уменьшается путем деления его на некоторый коэффициент, больший 1 (импирически установлено, что этот коэффициент лучше всего взять равным приблизительно 1.247). Однако в отличие от сортировки Шелла, при сортировке  "расчесыванием", когда дело уже дойдет до сравнения соседних элементов массиива, остается в точности не известно, сколько же еще раз надо пройти массив, сравнивая соседние элементы, чтобы он оказался полностью отсорированным. Но это число будет уже совсем небольшим (обычно остается сделать всего несколько проходов).

Подробно сортировка Шелла и сортировка "прочесыванием" будут рассмотрены на практическом занятии.

# Лекция 3

## Сортировка перемешиванием (двунаправленная "пузырьковая" сортировка)

При сортирвке методом "пузырька" при первом проходе максимальный элемент массива перемещается в самый его конец. После второго прохода на предпоследнем месте окажется второй по величине элемент массива, и т.д.

Таким образом, каждый раз остается только отсортировать (тем же способом) оставшуюся часть массива (без элементов массива в его конце, уже находящихся на "своих" местах).

Тут важно на каждом новом проходе уменьшать на 1 величину верхнего предела переменного индекса массива с тем, чтобы не выполнять бесполезных сравнений в уже отсортированной части массива.

Но можно таже, сделав проход по массиву слева направо, в результате которого наибольший элемент переместится в его конец, сделать затем аналогичный проход справа налево, в результате которого наименьший элемент переместился бы в начало. Таким образом, чередуя проходы "слева направо" с проходами "справа налево", можно будет уменьшать оставшуюся неотсортированной часть массива сразу с двух сторон.

Такую модификацию "пузырьковой" сортировки назвают сортировкой "перемешиванием", или "шейкерной" сортировкой.

Реализация этого алгоритма может быть следующей.

```julia
function mixersort!(a)
    i_beg = 1
    i_end = length(a)
    while i_beg < i_end
        @inbounds for i in i_beg:i_end-1 # макрос @inbounds отменяет контроль выхода за пределы массива
            if a[i] > a[i+1]
                a[i], a[i+1] = a[i+1], a[i]
            end
        end
        i_end -= 1
        @inbounds for i in i_end:-1:i_beg+1 # i меняется в сторону уменьшения (в диапазоне шаг отрицательный)
            if a[i-1] > a[i]
                a[i-1], a[i] = a[i], a[i-1]
            end
        end
        i_beg += 1
    end
    return a
end
```

**Замечание.** Данный алгоритм может быть улучшен, если после каждого "прохода" пороверять наличие факта перестановки элементов массива при этом "проходе", и в случае отсутствия данного факта сразу завершать сортировку (см. "пузырьковую" сортировку).

Ассимптотическая сложность сортировки перемешиванием, очевидно, является такой же как и у "пузырьковой" сортировки, т.е. $O(N^2)$.

## Быстрая (O(Nlog(N)) сортировка Хоара

Визуализацию идеи быстой сортировки можно посмотреть, например, [здесь](https://ru.wikipedia.org/wiki/Быстрая_сортировка)

```julia
function quick_sort!(A)
    length(A) <= 1 &&  return A
    N = length(A)
    left, right = part_sort!(A, A[rand(1:N)]) # - "базовый" элемент массива выбирается случайнам образом
    quick_sort!(left) # передача среза по ссылке исключает лишние аллокоции (коприрования)
    quick_sort!(right)
    return A
end

function part_sort!(A, b)
    N = length(A)
    K, L, M = 0, 0, N
    #ИНВАРИАНТ: A[1:K] < b && A[K+1:L] == b && A[M+1:N] > b
    @inbounds while L < M # макрос @inbounds отменяет контроль выхода за пределы массива
        if A[L+1] == b
            L += 1
        elseif A[L+1] > b
            A[L+1], A[M] = A[M], A[L+1]
            M -= 1
        else # if A[L+1] < b
            L += 1; K += 1
            A[L], A[K] = A[K], A[L]
        end
    end
    return @view(A[1:K]), @view(A[M+1:N]) # 1:K и M+1:N - эти диапазоны индексов определяют ещё не отсортированные части массива A
end
```

**Замечание 1.** Быстрая сортировка Хоара так же может быть реализована бутем разделения массива не на 3 части, а - только на 2: в левую часть должны быть перемещены все элементы, меньшие заданногоо базового элемента, а в правую - все элементы, большие или равные ему.

Реализация этой идеи потребует изменения функции part_sort!, в которой сновной цикл может быть спроектировн на основе следующего инварианта:

```julia
    K, L = 0, N
    #ИНВАРИАНТ: A[1:K] < b && A[L+1:N] >= b
    while K < L
        ...
    end
```

**Замечание 2.** Используемую в quick_sort! вспомогательную функцию part_sort! можно немного изменить, сделав так, чтобы она возвращала не ссылки на полученные части массива (которые затем требуется отсортировать независимо друг от дуга), а два соответствующих этим чсатям массива диапазона индексов, следующим образом.

```julia
@inline function part_sort!(A, index_range::AbstractUnitRange, b)
    K, L, M = index_range[1]-1, index_range[begin]-1, index_range[end] # 0, 0, N
    #ИНВАРИАНТ: A[index_range[begin]:K] < b && A[K+1:L] == b && A[M+1:index_range[end]] > b
    @inbounds while L < M 
        if A[L+1] == b
            L += 1
        elseif A[L+1] > b
            A[L+1], A[M] = A[M], A[L+1]
            M -= 1
        else # if A[L+1] < b
            L += 1; K += 1
            A[L], A[K] = A[K], A[L]
        end
    end    
    return index_range[begin]:K, M+1:index_range[end] # - эти диапазоны индексов определяют ещё не отсортированные части массива A
end
```

Основной цикл в теле этой функции при этой её модификации не подвергся никаким изменениям.

При этом в код функции quick_sort! пришлось бы внести следующие изменения:

```julia
function quick_sort!(A, index_range=firstindex(A):lastindex(A))
    length(A) <= 1 &&  return A
    N = length(A)
    left_range, right_range = part_sort!(A, index_range, A[rand(1:N)]) # - "базовый" элемент массива выбирается случайнам образом
    quick_sort!(A, left_range) # передача среза по ссылке исключает лишние аллокоции (коприрования)
    quick_sort!(A, right_range)
    return A
end
```

Здесь в список аргументов функции пришлость добавить ещё аргумент range_index, через который в функцию можно будет передавать диапазон индексов той части массива, которую требуется отсортировать. По умолчанию этот диапазан равен диапазону всех индексов массива,поэтому данную функцию по-прежнему можно будет вызывать с одним аргументом (если требуется отсортировать весь массив целиком).

Такой вариант функции part_sort! делает её более универсальной. Так это позволит теперь использовать её не только для реализации алгоритма быстрой сортировки Хоара, но и в алгоритме Хоара быстрого вычисдения медианы массива, который будет рассмотрен далее.

### Оценка сложности алгоритма Хоара

На каждом шаге алгоритма происходит разделение массива на 3 неперерывные части: леваячасть, все элементы которой меньше выбранного базового элемента, средняя часть, все элементы которой равны базовому элементу, и правая часть, все элементы которой больше базового элемента.

Если средняя часть всегда состоит ровно из одного элемента (так будет, если в массиве нет повтряющихся элементов), то это будет соответствать наихудшему случаю. Далее, для простоты анализа среднюю чсть (состоящую из одного элемента) не будем исключать из дальнейшей сортирови, и будем ее относить, например, к правой части. Таким образом, будем считать, что на каждом шаге алшоритма происходит деление массива на две части: левую и правую, каждую из которых требуется далее отсортировать независимо друг от друга.

Для ещё большего упрощения анализа будем считать, что эти части имеют равную длину, хотя в действительности можно расчитывать лишь на приближенное равенство их длин, и то лишь в среднестатистическом смысле. Тогда процесс сортировки, каждый шаг которой приводит к делению массива на две равные части (точнее говоря, - приближенно равные, в среднестатистическом смысле). Наглядно это можно представить себе в виде двоичного дерева, корню которого соответсвует исходный массив, а каждому узлу соответствует некоторая часть массива, получающаяся делением более крупной части на две меньшие части.

Если число элементов в массиве есть некоторая степень 2, $N=2^m$, то высота такого дерева будет равна $m=log_2(N)$. Каждому ярусу этого дерева соответствует $N$ операций сравнения (грубо говоря). Поэтому весь алгоритм сортировки в этом случае потребует $N \log(N)$ операций сравнения. Т.е. его вычислительная сложность должна быть оценена как  элементарных операций (число которых в наихудшем случае пропорционально числу опраций сравнения).

Если же длина исходного массива не равна в точности некоторой степени двойки, то мы моглибы рассмотренть этот алгоритм в применении к массиву длины $N'>N$, которая есть длижайшее к $N$ натуральное число, равное некоторой степени двойки. Применительно к массиву длины $N'$ оценка сложности нами была получена. Ясно, что она не превышает сложности сортировки исходного массива длины $N$, при этом, в силу того, что $N'<2N$, имеем:

$$Сложность_сортировки_массива_длины_N <= O(N' \log(N')) <= O(2N\log(2N) = O(N\log(N))$$

## Порядковые статистики. Медиана массива

**i-ой порядковой статистикой$ - это значение i-го элемента отсортированного массива.

Порядковую статустику массива можно вычислить, не осуществляя его сортировку.

### Быстрое ($O(N)$) вычисление $i$-ой порядковой статистики

Быстое вычисление $i$-ой порядковой статистики может быть основано на вспомогательнй процедуре Хоара (названной нами ранее part_sort!). При этом, в отличие от соответствующей рекурсивной процедуры сортировки, вычисление порядковой статистики будет закончено, как только будет определен диапазон индексов соответствующий значению текущего базового элемента, содержащий заданный индекс $i$, т.е. такой, что  $K < i < M$.  В этом случае ответом, очевидно, будет $A[i]$. А пока средний диапазон, содержащий i, не найден, его поиск нужно будет продолжать только в той части массива (из двух оставшихся), в которой этот индекс содержится.

Таким образом, если при сортировке массива методом Хоара происходит как бы обход всего соответствующего двоичного дерева, то при вычислении порядковой статистики с заданнным индексом требуется только пройти по одной единственной ветке этого дерева. И для этого понадобится $N+N/2+N/4+N/8+...= O(N)$ операций сравнения.

```julia
function order_statistics!(A::AbstractVector{T}, i::Integer)::T where T
    function find(index_range)
        left_range, right_range = part_sort!(A, index_range, A[rand(index_range)]) # - "базовый" элемент массива выбирается случайным образом
        if i in left_range
            return find(left_range) 
        elseif i in right_range
            return find(right_range)
        else
            return A[i]
        end
    end
    find(firstindex(A):lastindex(A))
end

order_statistics(A, i) = order_statistics!(copy(A), i)
```

**Замечание 1.** Использование здесь варианта функции part_sort!, которая возвращала бы ссылки на соответствующие части массива было бы невозможным, т.к. индексация части массива, представленная с помощью ссылки на соответствующий срез исходного массива была бы уже другой.

**Замечание 2.** Быстрое ($O(N)$) вычисление первых (аналогично, - последних) $k$ порядковых статистик, если только $k$ не зависит от длины массива и не является слишком большим, возможно и без использования алгоритма Хоара.

Соответствующий алгоритм может выглядеть следующим образом.

```julia
function minimums(array, k)
    N = length(array)
    k_minimums = sort(array[1:k])
    i = k
    # ИНВАРИАНТ: issorted(k_mins) && k_mins - содержит k наименьших элементов в array[1:i]
    while i < length(array)
        i += 1
        if array[i] < k_minimums[end]
            k_minimums[end] = array[i]
            insert_end!(k_minimums)
        end
    end
    return k_minimums
end            

function insert_end!(array)::Nothing
    j = length(array)
    while j>1 && array[j-1] > array[j]
        array[j-1], array[j] = array[j], array[j-1]
        j -= 1
    end
end
```

### Медиана массива

**Медиана (середина) массива** - это порядковая статистика с индексом $(N+1)/2$, если длина массива $N$ - нечетная, или - среднее арифметическое порядковых статистик с индексами $N/2$ и $N/2+1$, если $N$ - четное.

Очевидно, что алгоритм Хоара дает быстрый ($O(N)$) алгоритм вычисления медианы.

## Быстрая сортировка слияниями

Быстрая сортировка слияниями осуществляется на основе следующей вспомогательной процедуры, осуществляющей слияние двух предварительно отсортирванных массивов в один отсортированный за $O(N1+N2)$, где $N1$, $N2$ - длины заданных отсортированных массивов. При этом это можно сделать без использования дополнителной памяти, что очень важно.

Сортировка слиянием базируется на следующей вспомогательной процедуре.

```julia
"""
merge!(a1, a2, a3)::Nothing

    ДАНО: length(a3) == length(a1)+length(a2) && issorted(a1) && issorted(a2)
    
    РЕЗУЛЬТАТ: issorted(a3)
"""
function Base.merge!(a1, a2, a3)::Nothing
    i1, i2, i3 = 1, 1, 1
    @inbounds while i1 <= length(a1) && i2 <= length(a2) # @inbounds - передотвращает проверки выхода за пределы массивов
        if a1[i1] < a2[i2]
            a3[i3] = a1[i1]
            i1 += 1
        else
            a3[i3] = a2[i2]
            i2 += 1
        end
        i3 += 1
    end
    if i1 > length(a1)
        a3[i3:end] .= @view(a2[i2:end]) # Если бы тут было: a3[i3:end] = @view(a2[i2:end]), то это привело бы к лишним аллокациям (к созданию промежуточного массива)
    else
        a3[i3:end] .= @view(a1[i1:end])
    end
    nothing
end
```

Собственно сортирвка слияниями может быть записаны следующим образом.

```julia
function merge_sort!(a)
    b = similar(a) # - вспомогательный массив того же размера и типа, что и массив a
    N = length(a)
    n = 1 # n - текущая длина блоков
    while n < N
        K = div(N,2n) # - число имеющихся пар блоков длины n
        for k in 0:K-1
            merge!(@view(a[(1:n).+k*2n]), @view(a[(n+1:2n).+k*2n]), @view(b[(1:2n).+k*2n]))
        end
        if N - K*2n > n # - осталось еще смержить блок длины n и более короткий остаток
            merge!(@view(a[(1:n).+K*2n]), @view(a[K*2n+n+1:end]), @view(b[K*2n+1:end]))
        elseif 0 < N - K*2n <= n # - оставшуюся короткую часть мержить не с чем
            b[K*2n+1:end] .= @view(a[K*2n+1:end])
        end
        a, b = b, a
        n *= 2
    end
    if isodd(log2(n)) # - если цикл был выполнен нечетное число раз
        b .= a  # b = copy(a) - это было бы не то же самое, т.к. тут получилась бы ссылка на новый массив, который создаст функция copy
        a = b
    end
    return a # - ссылка на исходный массив (проверить, что это так, можно с помощью ===)
end
```

### Оценка сложности алгоритма сортирвки слияниями

Алгоритму сортирови слияниями можно сопоставить двоичное дерево, визуально представляющее процесс слияний.

Если длина массива $N$ есть некоторая степень 2, то высота этого дерева будет равна $log_2(N)$. На каждом ярусе этого дерева выполняется $N$ сравнений, следователь  в этом  случае потребуется всего $N\log_2(N)$ операций сравнения.

Далее можно дословно повторить уже применявшееся ранее рассуждение.

Если длина исходного массива не равна в точности некоторой степени двойки, то мы могли бы рассмотреть этот алгоритм в применении к массиву длины $N'>N$, которая есть ближайшее к $N$ натуральное число, равное некоторой степени двойки.

Применительно к массиву длины $N'$ оценка сложности нами была получена. Ясно, что она не превышает сложности сортировки исходного массива длины $N$, при этом, в силу того, что $N'<2N$, имеем:

$$Сложность_сортировки_массива_длины_N <= O(N' \log(N')) <= O(2N\log(2N) = O(N\log(N))$$

## Быстрое возведение в степень

Пусть требуется вычислить целую неотрицательную степерь $a^n$ некоторого числа $n$ (на самом деле не обязательно числа, но и - матрицы, или многочлена, в общем, можно считать, что $а$ - это элемент какого-либо кольца).

Ясно, что это можно сделать за $O(n)$ операций умножения. Но возникает вопрос, а можно ли это сделать быстрее. Оказывается, что это всегда можно сделать за $log(n)$ операций, т.е. "быстро".

В частном случае, когда число $n$ - есть некоторая степень 2 это не вызывает вопроса. Например, вычислить $a^8$ можно всего за 3 операции умножения ($3=log_28$):

```julia
a2 = a*a
a4 = a2*a2
a8 = a4*a4
```

Или, когда $n$ есть произвольная степень двойки (целая не отрицательная), быстрый алгоритм возведения в эту степень мог бы выглядеть так:

```julia
# число n - есть некоторая целая неотрицательная степень 2
p, k = a, n
#ИНВАРИАНТ: p^k = a^n
while k != 1
    p *= p
    k ÷= 2 # k гарантированно делится на 2, т.к. по предположению n - степень 2
end
```

В случае, когда целое неотрицательное число $n$ не является степенью 2 напрямую приведенный алгоритм применить нельзя. Тут трудность будет состоять в том, что не всегда переменная $k$ будет делиться на 2.

Идея быстрого алгоритма в общем случае состоит в том, что если на некотором шаге рассмотренного выше алгоритма число k окажется нечетным, то вместо деления из него надо будет вычесть 1, а затем уже, на следующей итерации, оно гарантировано поделится на 2.

Эту идею можно реализовать следующим образом.

```julia
k, t, p = n, 1, a

#ИНВАРИАНТ: p^k*t=a^n 
while k>0
    if even(k) # k - четное
        k ÷= 2
        p *= p # т.к. p^k = (p*p)^k*(t/2)
    else
        k -= 1
        t *= p # т.к. p^k * t = p^(k-1)*(p*t)
    end   
end
#УТВ: t = a^n
```

Остается только понять, что сложность этого алгоритма попрежнему будет иметь оценку $O(\log(n))$. В самом деле, в наихудшем случае единицу придется вычитать через раз, при этом для числа повторений цикла очевидна оценка сверху $2\log_2(n)$, а это и есть $O(\log(n))$

## Эффективный алгоритм вычисления функции $log_a(x)$ с заданной точностью

Пусть требуется составить алгоритм вычисления логарифма $log_a(x)$ по некоторому основанию $a$. Для произвольного значения аргумента $x$ расчитывать на получения точного ответа, имеюя ввиду вычисления с плавающей точкой, не приходится. Поэтому задачу сформулируем так: для произвольно заданного значения аргумента $x$ и для заданной, сколь угодно малой величины абсолютной погрешности $\varepsilon>0$ найти значение $y: |\log_a(x)-y| <= \varepsilon$.

Для определенности будем считать $a>1$. Обозначим $\hat{y}=\log_a(x), \ \ \ \Delta = \hat{y}-y$, тогда

$$
x = a^{\hat{y}} = a^{y+\Delta}=a^ya^{\Delta}=a^{y}z^t
$$
где $z,t$ - новые переменные, выбором значений которых мы можем свободно распорядиться, лишь бы $a^{\Delta}=z^t$. А именно, имеем

$$
\Delta=t\log_az
$$

Откуда, исходя из требования $|\Delta|<=\varepsilon$, получаем

$$

|\Delta|=|t||\log_az|<=\varepsilon
$$

Для выполнения последнего неравенства достаточно, что бы $|t|<=\varepsilon$ и $|\log_az|<=1$. Откуда, учитывая, что $a>1$, находим явное условие для второй переменной $1/a <= z <= a$.

Т.е. если добиться того, что бы

$$
|t|<=\varepsilon, \ \ \ 1/a <= z <= a
$$

то задача будет решена, т.е. получится, что $∣\log_a(x)−y∣<=ε$

Соответствующий алгоритм выглядит следующим образом.

```julia
z, t, y = x, 1, 0
#ИНВАРИАНТ: a^y * z^t == x (=const)
while z > a || z < 1/a || t > ε   
    if z > a
        z /= a
        y += t # т.к. z^t = (z/a)^t * a^t
    elseif z < 1/a
        z *= a
        y -= t # т.к. z^t = (z*a)^t * a^-t
    else # t > ε
        t /= 2
        z *= z # т.к. z^t = (z*z)^(t/2)
    end
end
#УТВ: y: |log_a(x)-y| <= ε
```

**Замечание.** Если в этом алгритме изменить порядок проверки условий в теле цикла, сделав первой проверку условия t > ε, то это приведет к зацикливанию (почему?).

## Решение нелинейного уравнения методом деления отрезка пополам

Рассмотрим уравнение вида
$$f(x)=0,$$
где $f:\ [a;b]\to \mathbb{R}$ - некоторая непрерывная на отрезке $[a;b]$ функция, и при этом выполнены следующие два условия:

на открытом интервале $(a;b)$ уравнение имеет ровно один корень (этот интервал называют интервалом локализации корня);
на концах $[a;b]$ значения функции имеют противоположные знаки, т.е. $f(a)\cdot f(b)<0$.
Пусть задана максимально допустимая абсолютная погрешность $\varepsilon>0$, с которой требуется вычислить значение корня. Тогда задача сводится к тому, чтобы найти такой отрезок $[a^\prime; b^\prime]$, чтобы, во-первых, он содержал корень, и, во-вторых, его длина не превосходила бы величины $\varepsilon$. Тогда любую точку этого отрезка, например, его середину, можно принять за искомое приближенное решение уравнения.

Идея метода деления отрезка пополам для приближенного решения данного уравнения выражается в следующих пунктах:

- вычислить функцию в средне отрезка локализации корня;
- сравнивать знак полученного значения со знаком функции в одном из концов отрезка локализации, например, со значением на левом его конце;
- если знаки окажутся совпадающими, то левую половину отрезка локализации можно смело отбросить (там заведомо корня нет) и переместить левую границу отрезка локализации в среднюю его точку;
- если же знаки окажутся противоположными, то, наоборот, правую половину отрезка следует отбросить (т.к. корень только один), и правую границу отрезка локализации переместить на его середину.

Перечисленные пункы следует повторять до тех пор, пока длина отрезка локализации превышает заданую максимально допустимую погрешность.

Таким образом, если переменные $a$, $b$ считать фазовыми переменными цикла (изменяющимися в этом цикле), то условие $f(a)\cdot f(b)<0$ должно рассматриваться как его инвариант. При этом условие $b-a>\varepsilon$ есть условие продолжения цикла.

Соответствующая функция на языке Julia могла бы выглядеть так:

```julia
function bisect(f::Funcnion, a, b, ε)
    y_a=f(a)
    # ИНВАРИАНТ: f(a)*f(b) < 0 (т.е. (a,b) - содержит корень)
    while b-a > ε
        x_m = (a+b)/2
        y_m=f(x_m)
        if y_m==0
            return x_m
        end
        if y_m*y_a > 0 
            a=x_m
        else
            b=x_m
        end
    end
    return (a+b)/2
end
```

Вычислительная сложность рассмотренного алгоритма оценивается, очевидно, как $O(log((b-a)/\varepsilon)$, при $\varepsilon \to 0$.

## Наибольший общий делитель (НОД). Алгоритм Евклида

Пусть a, b - целые числа.

Их наибольший общий делитель, НОД(a,b) - это наибольшее положительное целое, являющееся делителем обоих чисел.

При этом дополнительно считается, что НОД(0,0)=0.

Ясно что,

- $\forall a,b \in \mathbb{Z} \ \ НОД(a,b) = НОД(b,a)$
- $\forall a \in \mathbb{Z} \ \  НОД(a,1)=1$
- $\forall a \in \mathbb{Z} \ \ НОД(a,0)=a$
- $\forall a,b \in \mathbb{Z} \ \ НОД(a,b) = НОД(a, -b)$
- $\forall a,b \in \mathbb{Z} \ \ НОД(a,b) = НОД(a,a+b) = НОД(a, a-b)$

### Алгоритм Евклида

```julia
# m, n - заданные целые
a, b = m, n
#ИНВАРИАНТ: НОД(a,b)==НОД(m,n)
while b != 0
    a, b = b, a % b # a % b - целочисленный остаток от деления a на b
end
#УТВ: b == НОД(m,m)
```

**Замечание.** В этом варианте алгоритма, если не ограничиваться только положителными a, b, ответ может получиться отрицательным, что легко поправить, взяв абсолютную величину.

### Расширенный алгоритм Евклида

**Теорема.** $\forall a,b \in \mathbb{Z}$ $\exist u,v \in \mathbb{Z}$, такие что $НОД(a,b) = ua + vb$.

Мы докажем эту теорему, спроектировав соответствующий алгоритм, основываясь на методе инварианта цикла.

Алгоритм, подобный алгоритму Евклида, который наряду с $НОД(a,b)$ вычисляет также и названные целые числа $u,v$, называется **расширенным алгоритмом Евклида**.

Для проектирования этого алгоритма применим метод инварианта цикла.

```julia
# m, n - заданные целые
a, b = m, n
u_a, v_a = 1, 0
u_b, v_b = 0, 1
#=
ИНВАРИАНТ: 
    НОД(m,n)==НОД(a,b)
    a = u_a*m + v_a*n 
    b = u_b*m + v_b*n
=#

while b != 0
    k = a÷b
    a, b = b, a % b 
    #УТВ: a % b = a-k*b - остаток от деления a на b
    u, v = u_a, v_a
    u_a, v_a = u_b, u_a
    u_b, v_b = u-k*u_b, v-k*v_b
end
#УТВ: b == НОД(m,m) == u_a*m + v_a*n
```

Алгорит построен, тем самым теорема доказана.

**Замечание 1.** На каждом шаге расширенного алгоритма Евклида требуется вычислять частное и остаток от деления целых чисел. Однако в языке Julia имеется встроенная функци divrem позволяющая получать и частное и остаток всего за одну операцию. С использование этой функции следующие строчки кода с двумя операциями % и ÷

```julia
k = a÷b
a, b = b, a % b 
```

могут быть заменены на код с одной единственной операцией divrem следущим образом:

```julia
k, r = divrem(a,b)
a, b = b, r
```

что является предпочтительным.

**Замечание 2.** В приведенном варианте расширеннного алгоротитма Евклида, также как и в рассмотренном выше простом алгоритме Евклида, не учтена возможность отрицательных значений чисел a, b. Но это очень легко поправить, только теперь, если понадобится изменять знак полученного наибольшего (по модулю) общего делителя с отрицательного на положительный, одновременно с этим должны изменияться знаки и коэффициентов u_a, v_a.

### Вычисление обратного элемента в кольце вычетов по модулю $n$

Практическая важность расширенного алгоритма Евклида состоит в том, что с его помощью можно находить обратные элементы в кольце вычетов по модулю $n$.

Как известно, элемент $m$ обратим в кольце вычетов по модулю $n$, если числа $m$, $n$ взаимно простые, т.е. если $НОД(m,n)=1$.

Таким образом, если $НОД(m,n) = um + vn,$ и если $НОД(m,n)=1$, то $um + vn=1,$ или $um\equiv 1 (mod\ n),$ т.е. если $m \in \mathbb{Z_n}$, то

$$m^{-1} = u (mod\ n)$$

**Замечание.** В языке Julia имеются встроенные функции gcd, gcdx, реализующие алгоритм Евклида и расширенный алгоритм Евклида, соответственно.

Также для работы с алгебраическими структурами, включая и кольцо вычетов целых чисел, у Julia имеется отдельный обширный пакет AbstractAlgebra (требующий предварительной установки и изучения).

# Лекция 4

- Встроенные целые типы (встроенная функция `typemax`).
- Пользовательский тип - кольцо вычетов целых чисел (`Residue`).
- Пользовательский тип - многочлен над кольцом или полем (`Polynomial`).
- Кольцо многочленов над некоторым полем.
- Вычисления с плавающей точкой (встроенные функции `floatmax`, `eps`, `maxintfloat`).

## Встроенные целые типы

Рассмотрим встроенные целые беззнаковые типы `UInt8`, `UInt16`, `UInt32`, `UInt64`.

Каждый из них представляют собой кольцо вычетов целых чисел по модулю `2^8`, `2^16`, `2^32` и `2^64`, соответственно, и, таким образом, значения этих типов принадлежат диапазонам: `0:2^8-1`, `0:2^16-1`, `0:2^32-1` и `0:2^64-1`.

Каждый из перечисленных диапазонов явлется представлением класса вычетов целых чисел по соответствующему модулю с помощью так называемой несимметриченой системы остатков.

Встроенные знаковые целые типы: `Int8`, `Int16`, `Int32`, `Int64` также передставляют собой те же классы вычетов по модулю `2^8`, `2^16`, `2^32` и `2^64`, соответственно. Но при этом классы вычетов будут представлены уже симметричными системами остатков, т.е. диапазонами: `-2^7:2^7-1`, `-2^15:2^15-1`, `-2^31:2^31-1`, `-2^63:2^63-1`, соответственно.

Таким образом, арифметические операции с целыми числами этих типов выполняются как с элементами той или иной системы остатков, представляющей соответствующий класс вычетов целых чисел.

Поэтому встроенные целые типы конечной длины не представляют кольцо всех целах чисел, а лишь моделируют опрерации с целыми числами. Причем, если в операциях участвуют слишком большие числа, то будут появляться ошибки переполнения, возможность которых всегда необходимо иметь ввиду.

Можно считать, что встроенный тип длинных целых `BigInt` реализует кольцо всех целых чисел, но вычисления с такими числами, по понятным причинам, являются очень затратными.

## Пользовательский тип - кольцо вычетов

Займемся теперь проектированием пользовательского типа данных, предназначенного для представления классов вычетов целых чисел по произвольному модулю (в виде несимметричной системы остатков).

```julia
struct Residue{T, M}
    value::T
    Residue{T,M}(value) where {T,M} = new(value ÷ M) 
end
```

Здесь нам пришлось переопределить конструктор типа `Residue`, определяемый по умолчанию, т.к. при присваивании полю `value` значения необходимо гарантировать, чтобы оно находилось в диапазоне `0:M-1`

Теперь, например, при создании объекта

```julia
a = Residue{Int,5}(7)
```

в поле value будет гарантировано записано число `2`.

Далее остается определить операции над элементами кольца вычетов

```julia
Base. +(a::Residue{T,M}, b::Residue{T,M}) where{T,M} = (a.value + b.value) ÷ M
Base. *(a::Residue{T,M}, b::Residue{T,M}) where{T,M} = (a.value * b.value) ÷ M

function Base.inv(a::Residue{T,M})::Union{Nothing, Residue{T,M}} where{T,M}
    #=
    Если элемент кольца вычетов a обратим, то обратный элемент может быть вычислен с использованием расширенного алгоритма Евклида (см. лекцию 3). В противном случае следует вернуть nothing
    =#
    ........................... # дальнейший код предлагается написать самостоятельно
end
```

Основываясь на функции inv целесообразно будет определить операцию деления

```julia
Base. /(a::Residue{T,M}, b::Residue{T,M}) where{T,M} = a * inv(b)
```

Так же может быть полезно определить в кольце вычетов унарный минус и, основанную на нем операцию вычитания:

```julia
Base. -(a::Reidue{T,M})where{T,M} = Residue{T,M}(M - a.value)

Base. -(a::Residue{T,M}, b::Residue{T,M}) = a + (-b)
```

Кроме этого, можно было бы определить ещё операции `==`, `===`, `<`, `>`, `<=`, `>=`, и дополнительно ещё операцию  сравнения (`==`) с `0` типа `Int64` (а также можно было бы определить ещё и операции сравнения с нулями всех остальных встроенных целых типов).

## Пользовательский тип - многочлен

```julia
struct Polynomial{T}
    coeff::Vector{T}

    function Polynomial{T}(coeff) where T 
        n = 0
        for c in reverse(coeff)
            if c == 0
                n+=1
            end
        end
        new(coeff[1:end-n])
    end
end
```

**ТУТ БЫЛО НЕ ХОРОШЕЕ УТВЕРЖДЕНИЕ: !!!! "В данном случае существующий конструктор по умолчанию нас вполне устраивает."**

Пример использования конструктора

```julia
p = Polynomial{Int}([1,2,3.0]) 
```

Естественно будет определить функцию, возвращающую порядок многочлена:

```julia
deg(p::Polinomial) = length(p.coeff) - 1
```

Далее, чтобы определить операции с многочленами, нужно договориться о том, в каком порядке перчисляются коэффициенты в векторе коэффицентов, т.е. - о том перечисляются они в порядке возрастания степеней, или наоборот - в порядке убывания.

Пусть, например, многочлены представляются последовательностями коэффициентов по возрастанию степеней, тогда:

```julia
function Base. +(p::Polinomial{T}, q::Polinomial{T})::Polinomial{T} where T
    np, nq = length(p.coeff), length(q.coeff)
    if  np >= nq 
        coeff = similar(p.coeff)
        coeff[1:nq] .= (@view(p.coeff[1:nq]) .+ q) 
    else
        coeff = similar(q.coeff)
        coeff[1:np] .= (p .+ @view(q.coeff[1:np]))
    end
    # При сложении некоторые старшие коэфициенты могли обратиться в 0 
    i, n = lastindex(coeff), 0
    while i > 0 && coeff[i] == 0
        n += 1
        i -= 1
    end
    # n = число нулей в конце массива coeff, соответсвующих старшим степеням  
    resize!(coeff, length(coeff)-n)
    return Polinomial{T}(coeff)
end
```

**Замечание.** Если бы многочлены представлялись последовательностями коэффициентов по убыванию степеней, то после сложения многочленов нули могут появиься в начале массива `coeff`. Тогда прежде чем применять к этому массиву функцию `resize!` (изменяющую размер массива), потребовалость бы сначала произвести сдвиг элементов массива `coeff` на соответствующее число позиций влево.

Тут уже требуется линейный сдвиг на `n` позиций влево, который мог бы быть произведен так:

```julia
coeff(1:end-n) .= @view(coeff[n+1:end])
```

Аналогично сложению многочленов можно определить и операцию их вычитания:

```julia
function Base. -(p::Polinomial{T}, q::Polinomial{T})::Polinomial{T} where T
    ....... # предлагается сделать это самостоятельно
end
```

```julia
function Base. *(p::Polinomial{T}, q::Polinomial{T})::Polinomial{T} where T
    coeff = zeros(T, deg(p) + deg(q)+1)
    for i in eachindex(p.coeff), j in eachindex(q.coeff)
            coeff[i+j - 1] += p.coeff[i]*q.coeff[j]
    end
    .....
    # Возможно, что коэффициет при старшей степени окажется равным нулю.
    # Поэтому предлагается самостоятельно вставить на место многоточий соответствующий код, 
    # в котором это проверялось бы, и, при необходимости, лишние нулевые элементы массива удалялись бы.
    return Polinomial{T}(coeff)
end
```

Кроме этого, было бы удобно предусмотреть ещё сложение, вычитание и умножение многочленов, когда один из них представлен просто числом (число тоже можно стчитать многочленом)

```julia

Base. +(p::Polinomial{T}, c::T) where T = +(p, Polinomial{T}([c]))
Base. +(c::T, p::Polinomial{T}) where T = +(Polinomial{T}([c]), p)

Base. -(p::Polinomial{T}, c::T) where T = -(p, Polinomial{T}([c]))
Base. -(c::T, p::Polinomial{T}) where T = -(Polinomial{T}([c]), p)

Base. *(p::Polinomial{T}, c::T) where T = *(p, Polinomial{T}([c]))
Base. *(c::T, p::Polinomial{T}) where T = *(Polinomial{T}([c]), p)

Далее, поскольку многочлены с коэффициентами из некоторого поля можно делить "уголком", получая частное и остаток в виде соответствующих многочленов, то полезными будут также определения следующих функций.

```julia
Base.div(p::Polinomial{T}, q::Polinomial{T})::Polinomial{T}where T = divrem(p,q)[1]
Base.rem(p::Polinomial{T}, q::Polinomial{T})::Polinomial{T}where T = divrem(p,q)[2]
```

Предполагается, что эти функции определены на основе функции `divrem(p,q)`, которую надо написать обобщенно, так, чтобы она могла быть использована для многчленов с коэффициентами из любого заданного поля (например, $\mathbb{R}, \mathbb{Q}, \mathbb{C}, \mathbb{F}_p$), представленного соответствующими встроенными  (`Float64`, `Rational`, `Complex`) или  пользовательскими (`Residue`) типами.

Наконец, для типа `Polinomial` было бы естественно обеспечитить возможность писать код в следующем стиле.

```julia
P = Polinomial{Int,[1,2,3]}
x = 0.5
y = P(x) # чтобы вычислить 1 + 2x + 3x^2
```

Это означает определить возможность "вызова объекта" (в данном случае - многочлена) на вычисление с данным значением аргумента `(x)`.

Такая возможность появится после следующего определения.

```julia
(p::Polinomial)(x) = polyval(reverse(p.coeff), x)
```

Смысл этого определения состоит в том, что оператор "вызова" представляет собой круглые скобки (в общем случае пустые или содержащие целый список аргументов), в данном случае это - `(x)`, применяется не к функции, как это бывает обычно, а к объету. Какие именно действия следует произвести с объектом и полученным аргументом записано справа от знака равенство.

В принципе, если бы эти действия не выражались бы всего лишь одной стокой, то их можно было бы записать точно также, как в таком случае это делается при определении функции:

```julia
function (p::Polinomial)(x) 
    polyval(reverse(p.coeff), x)
end
```

Только здесь вместо имени функции - объект с обязательным указанием его типа.

**Замечание.** Для работы с многочленами в Julia имеется пакет Polynomials.jl (который требует предварительной установки).

## Пользовательский тип - кольцо  вычетов многочленов над некоторым полем по заданному модулю

Чтобы работать с кольцом вычетов многочленов, нового типа определять не надо. Ранее определенный тип `Residue{T, M}` позволяет определить кольцо вычетов множества всех многочленов над каким либо полем по заданному модулю (в данном случае модулем будет некоторый  многочлен над тем же полем).

Например,

```julia
P = Residue{Rational{Int}, Polinomial{Rational{Int}, Rational[1,2,3]}}(Rational[1,2,3,4,5,6])
```

Теперь объект `P` передсдавляет многочлен с рациональными коэффицтентами, являющийся остатком от деления многочлена с коэффициентами `Rational[1,2,3,4,5,6]` (рациоальными), на многочлен с коэффициентами `Rational[1,2,3]` (рациональными).

## Вывод значений, функция display

В языке Julia для каждого типа данных, как встроенного, так и пользовательского определена (изначально) функция display. Эта функция автоматически вызывается всякий раз, когда значение того или иного типа выводится на экран (в REPL), причем формат, в котором значение выводися определяется функцией display.

Если мы определили новый тип данных, например, Polynom, то для него функция display будет определена по умолчанию.

Например,

```julia
julia> Polynomial{Int}([1,2,3])
Polynomial{Int64}([1, 2, 3])
```

Здесь была вызвана определенная по умолчанию функция функция display (поскольку в конце ввода не была поставлена точка с запятой, которая предотвратила бы этот вызов), и эта функция просто напечатала строку: "Polynomial{Int64}([1, 2, 3])".

Однако было бы нагляднее, если бы она вместо этого напечатала бы: "1+2x+3x^2".

Для обеспечения такого результата функцию display потребуется переопределить для нашего типа:

```julia
function Base.display(p::Polynomial)
    if isempty(p.coeff)
        return ""
    end
    str = "$(p.coeff[1])" # $(...) - означает "интерполяцию стоки", т.е. вставку в строку некоторого вычисляемого значения 
    for i in 2:length(p.coeff)
        if i > 2
            s = " + $(p.coeff[i])x^$(i-1)"
        else
            s = " + $(p.coeff[i])x"
        end
        str *= s
    end
    println(str)
end
```

В результате будет получиться вывод в виде:

```julia
julia> Polynomial{Int}([1,2,3])
1 + 2x + 3x^2
```

## Компьютерные числа с плавающей точкой

В языке Julia `Float64` - основной тип с плавающей точкой (соответствует типу double в C/C++).

Более короткие числа с плавающей точкой в серьезных вычислениях обычно не используются, так как не могут обеспечить численной устойчивости (численная устойчивость - это когда накопление ошибок округления всегда остается в приемлемых границах). Обычно они используются лишь для экономии памяти при представлении больших массивов данных, например, изображений.

Во внутреннем машинном представлении число с плавающей точкой представляется в виде знакового бита, двоичного кода порядка двоичного порядка $p$ числа и двоичного кода мантиссы $m$: $\pm m*2^p$.

Причем $1 \le m < 2$ - это условие означает, что мантиса представляется в так называемом **нормализованном** виде (сама мантисса в таком случае называется **нормализованной мантиссой**).

Чтобы получить строку из `64` битов, представляющих машинное число с плавающей точкой можно воспользоваться встроенной функцией `bitstring`, например:

```julia
julia> bitstring(2.2)
"0100000000000001100110011001100110011001100110011001100110011010"
```

Длина двоичной мантиссы зависит от типа данных, для Float64 она равна `53` битам. На самом деле в памяти хранится только `52` бита нормализованной мантиссы, т.к. ее первый бит всегда равен `1` и хранить его в памяти не имеет смысла. Оставшиеся `11` бит представляют двоичный порядок, который в памяти хранится в виде беззнакового целого. Однако это просто удобный способ кодирования, в действительности диапазон порядов нормализованных чисел типа `Float64` в перещете на десятичную систему счисления есть `-308:308`.

В Julia имеются встроенные функции `floatmin` и `floatmax`, возвращающие наимменьшее и наибольшее комьютерное нормализованное число с плавающей точкой заданного типа.

Напимер,

```julia
julia> floatmin(Float64)
2.2250738585072014e-308

julia> floatmax(Float64)
1.7976931348623157e308
```

Представить с помощью `Float64` число большее `floatmax(Float64)` не возможно. Однако существует значение данного типа, большее любого числа с плавающей точеой, но это не число, это значение `Inf` ("бесконечность"), которому тоже соответствуюе некоторый двоичный код.

Однако среди значений `Float64` имеются значения, меньшие `floatmin(Float64)` - это так называемы денормализованные числа, отрицательный порядок которых по абсолютной величине может превышать число `308`, но только за счет уменьшения длины мантисы (в этом и проявляется эффект денормализации). Наименьшее положительное денормализованное число приблизительно равно `2`.`5e-323`, т.е. на `15` порядков меньше минимального нормализованного числа.

Денормалиованные машинные числа могут появляться при делении какого-либо не большого числа на очень большие числа или при умножении на очень маленькие числа, и это явление будет приводить к потери точности вычислений.

Множество всех действительных чисел отображается на множество машинными числами с плавающей точкой (типа `Float64`, например), причем это отображение не взаимно однозначное.

Так все вещественные числа из диапазона от `-2e-324` до `2e324` (границы диапазона указаны приблизительно), отображаются в `0.0`. И этот диапазон вещественных чисел принято называть **машинным нулем**.

Всем положительным вещественным числам, по модудулю большим `floatmax(Float64)`, соответствует символ `Inf`, а всем отрицательным вещественным числам, по модулю большим, все того же значения `floatmax(Float64)` - соответствует значение `-Inf` (типа `Float64`).

Множество вещественных числ модули которых находятся между верхней границей машинного нуля и значением `floatmax(Float64)` также не взаимнооднозначно отображаются на множество машинных числел, которых имеется лишь конечное множество (хотя очень и очень большой мощности).

Поскольку длина мантиссы всегда `53` бита (если не брать в расчет денормализованные числа, которые на числовой оси располагаются рядом с машинным нулем), то при увеличении положительного двоичного порядка числа на `1` расстояния между соседними машинными числами (в пределах постоянного порядка) уменьшатся вдвое. А при уменьшении отрицательного порядка на `1`, наоборот, расстояния между соседними машинными числами уменьшается вдвое. Таким образом, машинные числа на числовой оси распределены не равномерно и тем гуще, чем ближе они к машинному нулю (внутри диапазона мшинного нуля имеется ровно одно машинное число - это сам ноль).

Для определения расстояния между соседними машинными числами в окрестности данного числа с плавающей точкой имеется встроенная функция `eps`. Например,

```julia
julia> eps(1.0)
2.220446049250313e-16

julia> eps(10.0)
1.7763568394002505e-15

julia> eps(0.1)
1.3877787807814457e-17

julia> eps(0.0)
5.0e-324
```

При этом величину `eps(1.0)` обычно называют "машинным эпсилон" (не путать с "машинным нулем").

Машинное эпсилон характеризуется тем, что это наибольшее из всех положительных машинных чисел,
для которых выполняется равенство:

```julia
1.0 + eps(1.0)/2 = 1.0
```

Для обычной (не компьютерной арифметики) такое равенство не возможно. Однако в компьютерной арифметике оно будет иметь место. Происходит это потому, что для сложения двух компьютерных чисел сначала необходимо привести их к одному порядку (большему), а затем уже складывать мантиссы. Но при увеличении порядка числа, его мантиссу приходится сдвигать влево по разрядной сетке, в результате чего в начале мантиссы будут появляться нули, а ее конец будет выходить за разрядную сетку, с потерей части значащих цифр. Поэтому, если двоичные порядки чисел различаются на `53` и более (это соответствует примерно 16 десятичным разрядам: $2^{-53}\approx 10^{-16}$), то тогда уже вся мантисса полностью сместится за пределы разрядной сетки, и при сложении мантисс фактически произойдет поразрядное суммирование с нулями.

## Причины погрешностей арифметики с плавающей точкой

Подведем итог всему сказанному ранее относительно особенностей арифметики с плавающей точкой, выделив следующие причины возможных погрешностей.

- **Потеря точности** - связана с уменьшением числа верных цифр мантиссы. Происходит в результате сложения чисел, сильно различающихся порядков, а также при умножениях и делениях, приводящих к денормализации мантиссы результата операции.

- **Переполнение** - это когда положительный порядок результата арифметических действий превышает максимально возможное значение, т.е. результат по абсолютной величине становится равным `Inf`. Происходит в результате перемножения очень больших чисел, или в результате деления больльшого числа на очень маленькое.

- **Исчезновение порядка** - это когда отрицательный порядок результата арифметических действий по абсолютной величине превышает максимально возможное значение, т.е. результат получается чрезвычайно маленький (и денормализованный). Происходит в результате перемножения очень маленьких чисел, или в результате деления маленького числа на очень большое.

Имеют место соотношения:

```julia
1/0.0 == Inf
1/Inf == 0.0
1/0.0 == Inf
Inf*Inf == Inf
Inf/Inf == NaN
0.0/0.0 == NaN
0.0*Inf == NaN
Inf^0 == 1.0    # !!!
Inf^Inf == Inf
```

где `NaN` - это значение с плавающей точкой, не представляющее никакое число.

Все арифметические операции, имеющие хотя бы один аргумет со значением `NaN`, всегда дают в результате `NaN`.

## Тип Complex

Для работы с комплексными числами в Julia имеется встроенный параметрический тип Complex{T}, где T <: Number  - тип вещественной и мнимой частей.

Примеры записи комплексных чисел

```julia
1+3im
2.0 + 0.5im
1//2+3//2im
```

Для комплексных значений определены, например, все арифметические операции, а также функции abs, angle, real, imag. Многие встроенные математические функции, такие как sin, cos, exp (и другие), также определены и для комплексных значений.

# Лекция 5

## Численное решение СЛАУ методом Жордана-Гаусса

Пусть имеется СЛАУ, которую запишем в матричном виде:
$$
Ax=b
$$
где $A$ - матрица размера $n\times n$, $b$ - вектор-столбец длины $n$, $x$ - неизвестный вектор-столбец. Будем считать при этом, что матрица системы не вырождена.

Как известно из линейной алгебры, метод Жордана-Гаусса состоит в том, что составляется так называемая расширенная матрица системы `[A b], затем эта матрица приводится к ступенчатому виду с помощью элементарных преобразований строк матрицы (это часть процедуры принято называть "прямым ходом" метода Жордана-Гаусса), после чего найти решение системы уже просто, с помощью так назыаемого "обратного хода".

Однако численное решение СЛАУ на компьтере сопряжено с погрешностями, присущими арифметике с плавающей точкой. В ряде случаев, особенно при решении очень больших систем, эти погрешности могут достигать кактастрофических величин.

Рассмотрим причины этого более подробно. Сначала вспомним, что собой представляют элементарные преобразования строк расширенной матрицы, с помощью которых матрица приводится к ступенчатому виду.

Если матрица СЛАУ не вырожденная, то при приведении расширенной матрицы к ступенчатому виду на главной диагонали должны получаться ненулевые элементы, а все элементы ниже главной диагонали должны обнуляться.

Это достигается с помощью некоторой последовательности из следующих двух элементарных преобразований

- перестановка каких-либо двух строк расширенной матрицы
- замена $k$-ой строки расширенной матрицы суммой этой строки с какой-либо $i$-ой строкой ($i\ne k$), умноженной на некоторый коэффициет (будем обозначать такой коэффициент буквой $t$).

Цель первого преобразования состоит в том, чтобы в позиции $(i,i)$ получить ненулевой элемет (сейчас мы поймем, что, на самом деле, надо, чтобы он был не просто ненулевым, а - как можно большим по модулю).

Цель второго преобразования состоит в том, что бы применяя его последовательно для $k=i+1:n$, обнулить элементы матрицы под $(i,i)$-ой поцицией.

Для этого (уже после того как на $i$-ю позицию была перемещена нужная строка) указанный выше коэффициен $t$ для каждого $k=i+1:n$ должен вычисляться по формуле
$$
t=-\frac{a[k,i]}{a[i,i]}
$$

тогда, с учетом того, что в каждой $(i,j)$ позиции марицы в процессе вычислений накоплена некоторя ошибка, которую обозначим $\Delta_{ij}$, в позиции $(k,m)$, $m \in i:n$ имеем
$$
a[k,m]+\Delta_{k,m} + t\cdot(a[i,m]+\Delta_{i,m})
$$

и таким образом суммарная ошибка в этой позиции получается равной
$$
\Delta_{k,m} + t\cdot\Delta_{i,m}
$$

Таким образом, если величина $|t| >> 1$, то возможно быстрое нарастание погрешностей, и они могут достичь катастрофически больших величин.

Чтобы этого избежать, величина $t$ по абсолютной величине не должна превышать $1$. Для этого надо так перставлять строки в матрице, чтобы в очередной $(i,i)$-ой позиции оказывался элемент, не просто не равный $0$, а максимальный по абсолютной величине.

Вот численный пример.
![Рис. 2](lecture_2_4_fig-2.png)
Окончательный результат прямого хода метода Жордана-Гаусса
![Рис. 3](lecture_2_4_fig-3.png)

**Замечание.** На самом деле только одного предплодожения о невырожденности матицы системы не достаточно для того, чтобы получить решение методом гаусса с приемлемой точностью. Дело в том, что бывают так называемые плохообусловленные матрицы, которые могут быть и не вырожденными, но, тем не менее, погрешносити решения соответствующих СЛАУ методом Гаусса могут достигать катастрофически больших значений. Но более подробное обсуждение самого понятия и методов решения плохообусловленных СЛАУ выходят за пределы нашего курса.

## Некоторые алгоритмы вычислительной геометрии

- Выбор типа данных для представления точек (плоскости).
- Задача поиска точки пересечения (если она есть) двух заданных отрезков на плоскости.
- Задача вычисления угола между двумя плоскими прямыми.
- Задача определения, лежат ли две заданные точки плоскости по одну сторону от заданной границы области; в частности - по одну сторону от заданной прямой.
- Задача определения, лежит ли заданная точка плоскости внутри заданного выпуклого многоугольника.
- Задача определения, является ли заданный плоский многоугольник выпуклым.
- Задача построения выпуклой оболочки заданного множества точек плоскости.
- Задача вычисления ориентированной площади плоского многоугольника (любого).

## Выбор типа данных для представления точек (плоскости)

В языке Jula имеется несколько возможностей определить тип данных для представления точек плоскости.

- Точки можно представлять двухэлементными веторами `Vector{<:Real}`, например:

```julia
P=[0,0]
```

- Точку можно задать как двухэлементный кортеж `Tuple{T,T} where T<:Real`, например:
  
```julia
P=(0,0)
```

- Точку можно задать как структуру с двумя однотипными числовыми полями:

```julia
struct Vector_2D{T<:Real}
    x::T
    y::T
end
```

наример:

```julia
P=Vector_2D(0,0)
```

- Точку можно задать как именованный кортеж `NamedTuple{(:x, :y), Tuple{T,T}} where T<:Real`. Приэтом для этого типа удобно будет определить псевдоним:

```julia
Vector2D{T<:Real}=NamedTuple{(:x, :y), Tuple{T,T}}
```
  
наример:

```julia
P = (x=0,y=0)
```

или то же самое можно ещё и так:

```julia
P=Vector2D{Int}((0,0))
```

**Замечание.** Точку можно задать как значение параметрического типов, определенных пакете [StaticArrays.jl](https://juliaarrays.github.io/StaticArrays.jl/latest/), а именно типа `SVector`, или типов, производных от парметрического типа `FieldVector`.

Однако осставим этот способ за скобками, поскольку изучение этого пакета отвлекло бы нас от главной цели.

Мы остановимся на способе представления точки плоскости с помощью именованных кортежей (`NamedTuple`).

Отметим, что тип `NamedTuple` представляет собой просто некоторую "обёртку" вокруг типа `Tuple` с соответствующим (фиксированным) числом элементов.

Обращаться к элементам именованного кортежа мощжно как с помощью индексов, например, `A[1], A[2]`, или с помощью их имен, например, `A.x, A.y`.

Координаты точек полоскости - суть координаты соответствующих радиус-векторов. Поэтому не будем делать различий между точками и их радиусветорами. В соответствии с этим определим необходимые операции для представляющего их типа `Vector2D`.

```julia
using LinearAlgebra

Vector2D{T<:Real} = NamedTuple{(:x, :y), Tuple{T,T}}

Base. +(A::Vector2D{T},B::Vector2D{T}) where T = Vector2D{T}(Tuple(A).+Tuple(B))

Base. -(A::Vector2D{T}, B::Vector2D{T}) where T = Vector2D{T}(Tuple(A) .- Tuple(B))

Base. *(coeff::T, A::Vector2D{T}) where T = Vector2D{T}(coeff.*Tuple(A))

LinearAlgebra.norm(A::Vector2D) = norm(Tuple(A))
# norm(a) - длина вектора, эта функция опредедена в LinearAlgebra

LinearAlgebra.dot(A::Vector2D{T}, B::Vector2D{T}) where T = dot(Tuple(A), Tuple(B))
# dot(a,b)=|a||b|cos(a,b) - скалярное произведение, эта функция определена в LinearAlgebra

Base. cos(A::Vector2D{T}, B::Vector2D{T}) where T = dot(A,B)/norm(A)/norm(B)

xdot(A::Vector2D{T}, B::Vector2D{T}) where T = A.x*B.y-A.y*B.x
# xdot(a,b)=|a||b|sin(a,b) - косое произведение

Base. sin(A::Vector2D{T}, B::Vector2D{T}) where T = xdot(A,B)/norm(A)/norm(B)
```

## Задача поиска точки пересечения двух отрезков на плоскости

Будем считать, что отрезки задаются координатами своих концов.

Точки плоскости будем представлять именованными кортежами типа `Vector2D`, определенного нами ранее.

Уравнение прямой, проходящей через точки $A$, $B$ может быть записано в виде:

$$
\frac{x-A.x}{B.x-A.x} = \frac{y-A.y}{B.y-A.y}
$$

или в более универсальном виде:

$$
(x-A.x)(B.y-A.y)=(y-A.y)(B.x-A.x)
$$

(теперь уже не надо будет заботиться о неравенстве нулю знаменателей).

Раскрыв здесь скобки, и приведя подобные члены, перейдем к канонической записи уравнения прямой, в котором все коэффициенты выражены через координаты заданных точек $A$ и $B$:

$$
(𝐵.𝑦−𝐴.𝑦)𝑥+(𝐴.𝑥−𝐵.𝑥)𝑦=𝐴.𝑦(𝐴.𝑥−𝐵.𝑥)+𝐴.𝑥(𝐵.𝑦−𝐴.𝑦)
$$

Чтобы проверить, что отрезки пересекаются и найти их точку пересечения, потребуется

- найти точку пересечения (если она есть) прямых, содержащих данные отрезки;

- проверить принадлежность найденной точки пересечения обоим отрезкам.

Пусть $[A_1, B_1]$ и $[A_2, B_2]$ - два рассматриваемых отрезка, концы которых представлеты типом `Vector2D`.

Тогда для нахождения точки пересечения содержащих их прямых требуется решить (если решение существует) следующую систему двух линейных уравнений:

$$
(𝐵_1.𝑦−𝐴_1.𝑦)𝑥+(𝐴_1.𝑥−𝐵_1.𝑥)𝑦=𝐴_1.𝑦(𝐴_1.𝑥−𝐵_1.𝑥)+𝐴_1.𝑥(𝐵_1.𝑦−𝐴_1.𝑦)\\
(𝐵_2.𝑦−𝐴_2.𝑦)𝑥+(𝐴_2.𝑥−𝐵_2.𝑥)𝑦=𝐴_2.𝑦(𝐴_2.𝑥−𝐵_2.𝑥)+𝐴_2.𝑥(𝐵_2.𝑦−𝐴_2.𝑦)
$$

Для представления отрезка введем новый тип данных

```julia
Segments2D{T<:Real} = NamedTuple{(:A, :B), Tuple{Vector2D{T},Vector2D{T}}}
```

И для этого типа определим функцию двух аргументов, возвращающую точку пересечения заданных отрезков, или значение `noting`, если пересечения нет.

```julia
function intersect(s1::Segment2D{T},s2::Segment2D{T}) where T
    A = [s1.B[2]-s1.A[2]  s1.A[1]-s1.B[1]
         s2.B[2]-s2.A[2]  s2.A[1]-s2.B[1]]

    b = [s1.A[2]*(s1.A[1]-s1.B[1]) + s1.A[1]*(s1.B[2]-s1.A[2])
         s2.A[2]*(s2.A[1]-s2.B[1]) + s2.A[1]*(s2.B[2]-s2.A[2]]

    x,y = A\b
    # !!!! Если матрица A - вырожденная, то произойдет ошибка времени выполнения

    if isinner((;x, y), s1)==false || isinner((;x, y), s2)==false
        return nothing
    end

    return (;x, y) #Vector2D{T}((x,y))
end

isinner(P::Vector2D, s::Segment2D) = (s.A.x <= P.x <= s.B.x || s.A.x >= P.x >= s.B.x) && 
                                     (s.A.y <= P.y <= s.B.y || s.A.y >= P.y >= s.B.y)
```

**Замечание.**
При написании этой функции мы исходили из того, что уравнение вида `A*z=b` имеет единственное решение (т.е. что матрица `A` - не вырожденная). Но, как мы знаем, если матрица вырожденная, то такое уравнение может не иметь вообще решений, или иметь их бесконечно много. Таким образом, если матрица окажется вырожденной, то при выполнеии нашей функции при выполнении операции `A\b` произойдет ошибка.

Но мы сознательно пошли на это, чтобы не усложнять алгоритм. При если, например, координаты точек брать случайными, то события, кодга наша матрица окажется вырожденной будут исчезающе редкими, что не трудно понять из общих вероятностных соображений (либо проверить экспериментально).

На самом деле, тут вопрос надо ставить несколько иначе.
Рассмотрим следующий рисунок ![рисунок 1](lecture_2_5_fig-1.png), на котором изображены графики двух почти параллельных прямых.

Из рисунка ясно, что в таких случаях погрешность вычисления координат точки пересечения прямых будет тем больше, чем меньше угол между ними.

Однако величина этого угла никак не связана с величиной определителя системы, т.е. если определитель равен `0`, то и угол, конечно равен `0`, но из малости величины определителя никак не следует малость угла.

В самом деле, уравнения любой системы можно умножать на некоторое не равное `0` число, от этого графики соответсвующих им прямых не изменятся, в то время как определитель изменится, и с помощью этого множителя может быть сделан сколь угодно малым.

Свойство матрицы системы, определяющее возможность получения достаточно точного её решения, адекватно выражается не её определителем, а другой характеристикой, называемой [**числом обусловленности** матрицы](https://ru.wikipedia.org/wiki/Число_обусловленности). Но обсуждение этих вопросов сейчас пока не будет входить в наши цели (эти вопросы рассматриваются в курсе вычислительной математики).

Отметим лишь, что в пакете `LinearAlgebra` имеется функция `cond`, вычисляющая число обусловленности заданной матрицы (чем число обусловленности больше, тем хуже, совсем плохо, когда это число достигает значений $10^{12}$ и выше).

## Задача определения угла между прямыми

Вычисления угла между направляющими векторами могут основываться или на вычислении их скалярно произведения, или - на вычислении так называемого косого произведении этих векторов.

В случае использования скалярного произведения, имеется возможность определить косинус угла между векторами.

А в случае использования косого произведения векторов - синуса угла между ними.

Что лучше - зависит от конкретной задачи.

Так, если искомый угол заведомо находится в диапазоне от 0 до 180 градусов, то целесообразно вычислять косинус этого угла (т.к. значения арккосинуса лежат в этом диапазоне).

Если же искомый угол заведомо по абсолютной величине не превосходит 90 градусов, то целесообразно вычислять синус этого угла.

**Замечание.** Часто бывает, что не нужно определять само значение угла, достаточно бывает лишь иметь возможность сравнить два угда по величине. В этом случае можно использовать непосредственно значения косиниусов или сунусов сравниваемых углов, если только значения рассматриваемых углов не выходят за пределы участков монотонности этих функций.

Для вычисления скалярного произведения векторов ранеее была определена функция

```julia
LinearAlgebra.dot(A::Vector2D{T}, B::Vector2D{T}) where T = dot(Tuple(A), Tuple(B))
```

### Косое произведение векторов

От векторного произведения двух векторов **косое произведение** отличается тем, что результатом будет не сам вектор, ортогональный плоскости, определяемой этими двумя векторами, а лишь коэффициент при нормали к этой плоскости.

Рассмотрим выражение векторного произведения через координаты векторов, лежащих в плоскости `OXY`

$$
\vec{a}\times \vec{b} =
\begin{vmatrix}
\vec{i} & \vec{j} & \vec{k}\\
a_x & a_y & 0\\
b_x & b_y & 0
\end{vmatrix}=(a_x\cdot b_y - b_x\cdot a_y)\cdot \vec{k}
$$

Откуда получаем выражение искомого косого произведения:

$$a_x\cdot b_y - b_x\cdot a_y$$

Ранее нами была определена соответствующая функция 

```julia
xdot(A::Vector2D{T}, B::Vector2D{T}) where T = A.x*B.y-A.y*B.x
```

## Задача определения, лежат ли две заданные точки плоскости по одну сторону от границы заданной области

### Случай, когда граница граница представляет собой некоторую прямую, разделяюшую плоскость на две полуплоскости

Пусть $s=[A, B]$, некоторый сегмент рассматриваемой прямой, и $P$, $Q$ - пара точек, про которые требуется ответить, лежат ли они по одну сторону от прямой, или нет.

Определим направляющий вектор прямой $\vec l=\overrightarrow{AB}$. Тогда, точки $P$, $Q$ лежат по одну сторону от прямой тогда и только тогда, когда угол между векторами $\vec l$, $\overrightarrow{AP}$ и угол между векторами $\vec l$, $\overrightarrow{AQ}$ имеют один и тот же знак (отложены в одну и ту же сторону от прямой).

Функция, возвращающая значение `true`, если точки лежат по одну сторону от заданной прямой может быть определена так:

```julia
function is_one(P::Vector2D{T}, Q::Vector2D{T}, s::Sedment2D{T}) where T 
    l = s.B-s.A
    return sin(l, P-s.A)*sin(l,Q-s.A)>0
end
```

### Более общий способ

Ту же задачу можно решить и другим, более оющим способом. Для этого должно быть задано уравнение границы некотрой области.

Пусть граница определена своим неявным уравнением

$$
F(x,y)=0
$$

где $F(x,y)$ - некотрая непрерывная функция.

В частности это уравнение может представлять собой и уравнеие прямой, проходящей через две точки $A,B$:

$$
(𝑥−𝐴.𝑥)(𝐵.𝑦−𝐴.𝑦)−(𝑦−𝐴.𝑦)(𝐵.𝑥−𝐴.𝑥)=0
$$

Тогда неравенство

$$
F(x,y)<0
$$

разбивает все точки плоскости на 2 области: для двух точек $P$, $Q$ лежащих в одной и той же области данное неравенство выполняется или не выполняется одновременно.

Тогда, если определить:

```julia
is_one_area(F::Function, P::Vector2D{T}, Q::Vector2D{T}) where T = (F(P...)*F(Q...)>0)
```

Здесь предполагается, что функция F - есть функция двух вещественных переменных, причем уравнение $F(x,y)=0$, определяет границу рассматривемой плоской области.

В частности, если речь идет о прямолинейной границе, определяемой некоторым сегментом (s::Segment2D), то функция F будет определена выражением

```julia
(𝑥−s.𝐴.𝑥)(s.𝐵.𝑦−s.𝐴.𝑦)−(𝑦−s.𝐴.𝑦)(s.𝐵.𝑥−s.𝐴.𝑥)
```

## Задача определения, лежит ли заданная точка плоскости внутри заданного выпуклого многоугольника

Один из возможных вариантов решения следующий.

Если многоугольник выпуклый, как это предполагается, то из любой его внутренней точки будут "видны" все его вершины. Во входном массиве, по предположению, эти вершины перечисляются в порядке обхода границы (в каком-то из двух возможных направлений, всё равно в каком).

Тогда можно найти знак угла между вектором, направленном из заданной точки на некоторую вершину границы, и вектором, направленном из той же точки на следующую (в порядке обхода) вершину границы. При этом выжен будет только его знак этого угла.

Очевидно, что многоугольник выпуклый, тогда и только тогда, когда не будет происходить изменение знака угла при полном таком переборе всех пар соседних вершин. Сложность алгоритма, очевидно, оценивается как $O(n)$, где $n$ - число вершин многоугольника.

## Задача определения, является ли заданный плоский многоугольник выпуклым

Возможен следующий алгоритм, с оценкой сложности $O(n)$, где $n$ - число вершин многоугольника.

Опять будем исходить из дополнительного предположения о том, что вершины перечисляются во входном массиве, в каком-то одном из двух возможных, порядке обхода границы.

Тогда можно последовательно перебирая вершины многоугольника вычислять соответствующие его углы. У выпуклого многоугольника все эти углы будут меньше 180 градусов (или, если будем вычислять внешние углы, то все они - больше 180 градусов). А у не выпуклого многоугольника обязательно найдутся, как углы меньшие, так и большие 180 градусов.

## Задача построения выпуклой оболочки заданного множества точек плоскости

Задача ставится так. Дан некоторый массив координат точек плоскости. Требуется определить, какие из этих точек являются вершинами наименьшего выпуклого многоугольника, содержащего все остальные точки. Это наименьший многоугольник и называется **выпуклой оболочкой** заданного набора точек плоскости.

Понятие выпуклой оболочки поясняет следующий рисунок ![рисунок 2](lecture_2_5_fig-2.png)

Нарисунке показано, что если в точки "забить гвоздики", и поверх всех гвоздиков надеть хозяйственную резинку, то эта резинка примет форму выпуклой оболочки заданных точек.

Расмотрим несколько популярных алгоритмов построения выпуклой оболочки.

### Алгоритм Джарвиса

![Рисунок 3](lecture_2_5_fig-3.png)

Этапы алгоритма

- В заданном массиве находится самая нижняя точка, обозначим её $P_1$, и выбирается начальное базовое направление $l_1$ (на рисунке вектор этого направления напрвлен по горизонтали врправо). Точка $P_1$ гарантированно войдет в выпуклую оболочку.
  
- Следующая точка, обозначим её $P_2$, которая гарантированно войдет в выпуклую оболочку, будет точка, направление на которую из точки $P_1$ с базовым направлением $\vec l_1$ будет составлять наименьший угол. После выбора этой точки следует выбрать новое базовое направлением $\vec l_2=\overrightarrow{P_1P_2}$.

- Далее каждая $k+1-ая$ точка, добавляемая в выпуклую оболочку, определяется как точка, угол между направлением на которую из $k$-ой точки, и $k$-ым базовым направлением $\vec l_k$ является минимальным.

Алгоритм завершается когда очередная точка выпуклой оболочки не совпадет с точкой $P_1$.

Сложность этого алгоритма в наихудшем случае, когда почти все заданные точки войдут в выпуклую оболочку, оценивается как $O(n^2)$, где $n$ - это число всех точек.

Однако, часто число точек, вошедших в выпуклую оболочку, много меньше числа всех точек. Если число всех точек выпуклой оболочки можно оценить функцией $O(g(n))$, то то оценка общей сложности алгоритма Джарвиса будет иметь вид $O(n\cdot g(n))$.
  
### Алгоритм Грехома

Алгоритм Грехома сводится к следующим этапам

- Находится базовая точка $P_1$ точно так же, как и в алгоритме Джарвиса, и выбирается то же самое базовое направление $\vec l_1$.
- Все остальные точки сортируются по возрастанию угла между вектором $\vec l_1$ и вектором $\overrightarrow{P_1P_k}$ для $k=2,3,...,n$.
  
- Далее в выпуклую оболочку гарантирваноо войдут следующие 2 точки, следующие в отсортированном порядке.
  
- Сдедующая точка, в отсортирванном порядке, помещается в выпуклую оболочку как бы временно. Т.е. эта точка помещается на вершину стека, в котором вконце-концов должна оказаться вся выпуклая оболочка, но следующих шагах алгоритма некоторые точки с вершины этого стека могут быть сняты. А именно, пусть в стеке уже имеется $k$ точек. Тогда прежде чем на его вершину будут помещена очередная точка, из него сначала должны быть извлечены все точки, наличие котрых делает "текущую оболочку" не выпуклой (под "текущей оболочкой" здесь понимается многоугольник, вершины которого находятся в данный момент в стеке и ещё одна его вершина - это новая точка из отсортированной последовательности точек).

Следующая серия рисунков поясняет работу данного алгоритма

![Рисунок 4](lecture_2_5_fig-4.png)

Так же работу этого алгоритма в динамеке можно посмотреть, например, [здесь](https://habr.com/ru/post/144921/)

## Задача вычисления ориентированной площади плоского многоугольника (любого)

Задача ставится так: дана последователность точек - вершин произвольного многоугольника (допускаются даже пересечения его сторон), заданная в порядке обхода, например, против часовой стрелке (или по часовой стрелке - это не принципиально). Задание направление обхода означает, что граница многоугольника является ориентированной. Требуется вычислить площадь этого многоугольника. Причем, если ориентация границы положительная (направление обхода против часовой стрелки), то и площадь будет положительной, в противном случае площади приписывается знак минус.

Известно несколько простых методов решения этой задачи.

- Метод трапеций, следующий рисунок поясняет суть этого метода
![рисунок 5](lecture_2_5_fig-5.png)
Двигаясь по границе многоугольника от вершины к вершине вдоль заданной ориентации границы, надо вычислять площади трапеций одна из боковых сторон которых есть некоторое ребро многоугольникам(см.рисунок), причем периметры этих трапеций надо рассмативать как ориентированные границы, ориентация которых задаётся ориентацией самого многоугольника. Просуммировав полощади трапеций с нужными знаками, найдём полощадь многоугольника. Вычислять площади треугольников удобнее всего с помощью косого произведения, т.е. с помощью написанной нами функции `xdot`.

- Метод треугольника. Этот метод аналогичен методу трапеций, только вместо трапеций используются треугольники. Суть этого метода поясняется на следующем рисунке
![рисунок 6](lecture_2_5_fig-6.png)

- Существует ещё формула Гаусса для площади многоугольника
[формула Гаусса](https://ru.wikipedia.org/wiki/Формула_Площади_Гаусса)

# Лекция 6

Элементы вычислительной геметрии (продолжение, начало в лекции 5)

## Задача определения, лежит ли заданная точка плоскости внутри заданного многоугольника

Подчеркнем, что речь идет о произвольном многоугольнике, не оязательно выпуклом.

**Утверждение 1.** Для любой точки плоскости, лежащей вне некоторого многоугольника, сумма всех углов, между векторами с началом в данной точке и с концами в смежных вершинах многоугольника (с учетом знака) равна нулю.

**Утверждение 2.** Для любой точки плоскости, лежащей внутри некоторого многоугольника, сумма всех углов, между векторами с началом в данной точке и с концами в смежных вершинах многоугольника (с учетом знака) равна 360 градусам.

Допустим сначала, что располжение внешней точки относительно многоугольника и сам многоугольник таковы, что любой луч, проведенный из этой точки пересекает границу многоугольника не более двух раз. Если луч пересекает многоугольник только один раз, то это значит, что он проходит через какую-то вершину многоугольника внешним образом. Ясно, что имеется по краней мере две таких вершины, которые условимся называть крайними. Мы сейчас могли бы также не исключать и случай, когда какая-либо сторона многоугольника лежит на луче, в этом случае "крайней" будем считать (для определенности) ближайшую к точке вершину.

В этом случае доказательство утверждения 1 очевидно. Если многоугольник и расположение внешней точки не обладают указанным свойством, тогда надо рассмотреть углы между лучами, проходящими через вершины, у которых обе инцидентные им стороны остаются с одной стороны от луча. Если нарисовать рисунок, до справедливость утверждения 1 тоже станет очевидной.

Аналогично можно доказать и утверждение 2.

**Замечание.** С учетом того, что вычисления будут осуществляться в арифметике с плавающей точкой, может возникнуть проблема сравнения суммы углов с $0$ или с $2\pi$. Однако, поскольку эта сумма не может иметь промежуточных значений между указанными величинами, то сравнивать можно с значением $\pi$: если сумма окажется окажется меньше, то это будет означать, что она равна $0$, а если - больше, то  - что она равна $2pi$.

## Задача построения выпуклой оболочки заданного множества точек плоскости

Задача ставится так. Дан некоторый массив координат точек плоскости. Требуется определить, какие из этих точек являются вершинами наименьшего выпуклого многоугольника, содержащего все остальные точки. Это наименьший многоугольник и называется **выпуклой оболочкой** заданного набора точек плоскости.

Понятие выпуклой оболочки поясняет следующий рисунок ![рисунок 2](lecture_2_6_fig-1.png)

Нарисунке показано, что если в точки "забить гвоздики", и поверх всех гвоздиков надеть хозяйственную резинку, то эта резинка примет форму выпуклой оболочки заданных точек.

Расмотрим несколько популярных алгоритмов построения выпуклой оболочки.

### Алгоритм Джарвиса

![Рисунок 3](lecture_2_6_fig-2.png)

Этапы алгоритма

- В заданном массиве находится самая нижняя точка, обозначим её $P_1$, и выбирается начальное базовое направление $l_1$ (на рисунке вектор этого направления напрвлен по горизонтали врправо). Точка $P_1$ гарантированно войдет в выпуклую оболочку.
  
- Следующая точка, обозначим её $P_2$, которая гарантированно войдет в выпуклую оболочку, будет точка, направление на которую из точки $P_1$ с базовым направлением $\vec l_1$ будет составлять наименьший угол. После выбора этой точки следует выбрать новое базовое направлением $\vec l_2=\overrightarrow{P_1P_2}$.

- Далее каждая $k+1-ая$ точка, добавляемая в выпуклую оболочку, определяется как точка, угол между направлением на которую из $k$-ой точки, и $k$-ым базовым направлением $\vec l_k$ является минимальным.

Алгоритм завершается когда очередная точка выпуклой оболочки не совпадет с точкой $P_1$.

**Оценка сложности.** Сложность алгоритма Джарвиса в наихудшем случае, когда почти все заданные точки войдут в выпуклую оболочку, оценивается как $O(N^2)$, где $N$ - это число всех точек.

Однако часто число точек, вошедших в выпуклую оболочку, много меньше числа всех точек. Если число всех точек выпуклой оболочки можно оценить функцией $O(g(N))$, то то оценка общей сложности алгоритма Джарвиса будет иметь вид $O(N\cdot g(N))$.

Например, если предположить, что N точек более-менее равномерно заполняют некоторую выпуклую область плоскости, то число точек, входящих её в выпуклую оболочку можно оценить как $g(N)=O(\sqrt(N))$.
  
### Алгоритм Грехома

Прежде всего вспомним понятие стека.

В программировании **стеком (stack)** называют абстрактный тип данных, представляющий набор элементов какого-либо типа, организованный по принципу LIFO (англ. last in — first out, «последним пришёл — первым вышел»). 

При работе со стеком используется протокол, состоящий из действий:

- проверить, является ли стек пустым;

- добавить (положить) в стек новый элемент; об этом говорят еще: поместить элемент на вершину стека;

- снять с вершины стека очередной элемент (возможно только, если стек не пустой);

Конкретная реализация стека может быть разной, например, он может быть реализован на основе динамического массива.

**Алгоритм Грехома** сводится к следующим этапам.

- Сначала надо найти базовую точку $P_0$, и выбираеть базовое направление $\vec l_0$ (точно так же, как это делалось в алгоритме Джарвиса).

- Все остальные точки сортируются по возрастанию угла между вектором $\vec l_0$ и вектором $\overrightarrow{P_0P_k}$ для $k=1,2,...,N$.
  
- Далее в выпуклую оболочку помещаютсяточки $P_1 и P_2$ (они гарантированно в неё входят).
  
- Каждая сдедующая в отсортирванном порядке точка помещается в выпуклую оболочку, но пока временно. Т.е. эта точка помещается на вершину стека, в который вконце-концов должна быть помещена вся выпуклая оболочка, но на следующих шагах алгоритма некоторые точки с вершины этого стека могут быть сняты.

А именно, пусть в стеке уже имеется $k$ точек. Тогда прежде чем на его вершину будут помещена очередная точка, из него сначала должны быть извлечены все точки, наличие котрых делает "текущую оболочку" не выпуклой (под "текущей оболочкой" здесь понимается многоугольник, вершины которого находятся в данный момент в стеке и ещё одна его вершина - это новая точка из отсортированной последовательности точек).

Следующая серия рисунков поясняет работу данного алгоритма

![Рисунок 3](lecture_2_6_fig-3.png)

Так же работу этого алгоритма в динамеке можно посмотреть, например, [здесь](https://habr.com/ru/post/144921/)

**Оценка сложности.**  Оценка сложность алгоритма Грехома определяется оценкой сложности алгоритма сортировки, поэтому можно считатать, что сложность оценивается как $N \log N$

**Указание для программирования.** Реализовать стек проще всего на базе динамическго массива и использовать функции: isempty, push!, pop!.

## Задача вычисления ориентированной площади плоского многоугольника

В данном случае речь идет о произвольном многоугольнике, не обязательно выпуклом.

Задача ставится так: дана последователность точек - вершин произвольного многоугольника (допускаются даже пересечения его сторон), заданная в порядке обхода, например, против часовой стрелке (или по часовой стрелке - это не принципиально). Задание направление обхода означает, что граница многоугольника является ориентированной. Требуется вычислить площадь этого многоугольника. Причем, если ориентация границы положительная (направление обхода против часовой стрелки), то и площадь будет положительной, в противном случае площади приписывается знак минус.

Известно несколько простых методов решения этой задачи.

### Метод трапеций

Следующий рисунок поясняет суть этого метода
![рисунок 4](lecture_2_6_fig-4.png)
Двигаясь по границе многоугольника от вершины к вершине вдоль заданной ориентации границы, надо вычислять площади трапеций одна из боковых сторон которых есть некоторое ребро многоугольникам(см.рисунок), причем периметры этих трапеций надо рассмативать как ориентированные границы, ориентация которых задаётся ориентацией самого многоугольника. Просуммировав полощади трапеций с нужными знаками, найдём полощадь многоугольника. Вычислять площади треугольников удобнее всего с помощью косого произведения, т.е. с помощью написанной нами функции `xdot`.

Пусть, например, $P_k=(x_k, y_k)$ и $P_{k+1$}=(x_{k+1},y_{k+1})$ - две соседние вершины многоугольника. При этом не важно в какой последовательности перечислены вершины многоугольника: по часовой стрелке (как на рисунке) или - против. От этого будет зависеть только знак результата. Если нас интересует именно площадь, то можно просто брать его абсолютную величину.

Тогда площать соответсвующей трапеции будет вычисляться по формуле 

$$
(y_{k}+y_{k+1})(x_{k+1}-x{k})/2
$$

(эта площадь будет иметь знак, игнорировать его нельзя).

### Метод треугольника

Этот метод аналогичен методу трапеций, только вместо трапеций используются треугольники. Суть этого метода поясняется на следующем рисунке
![рисунок 6](lecture_2_6_fig-5.png)

Пусть, например, $P_0=(x_0,y_0) - это координаты некоторой вершины многоугольника, выбранной (произвольным образом) в качестве базовой, и $$P_k=(x_k, y_k)$ и $P_{k+1$}=(x_{k+1},y_{k+1})$ - какие-либо две другие соседние вершины многоугольника. При этом также как и в методе трапеций не важно в какой последовательности перечислены вершины многоугольника: по часовой стрелке (как на рисунке) или - против. От этого также будет зависеть только знак результата.

Тогда площать соответсвующего треугольника может быть вычислена с помощью косого произведения вектров $P_k-P_0$ и $P_{k+1}-P_0$

(эта площадь также будет иметь знак, игнорировать который нельзя).

**Замечание.** Вид формул для вычисления площади трапеции в методе трапеций и - площади треугольника в методе треугольников не зависит от положения начала координат.

### Формула Гаусса

Существует ещё формула Гаусса для площади многоугольника
[формула Гаусса](https://ru.wikipedia.org/wiki/Формула_Площади_Гаусса)

**Замечание.** Для языка Julia имеется пакет [GeometryBasics]( https://juliageometry.github.io/GeometryBasics.jl/dev/), реализующий многие функции вычислительной геометрии.

## Работа с интерактивными блокнотами

### Блокнот Jupyter

Jupyter - это интерактивная вычислительная среда на базе web-браузера.

При этом эту среду можно интегрировать в VS Code, что делает работу в этой среде особенно удобной.

Название Jupyter происходит от начальтых букв языков программирования: Julia, Python, R.

После запуска Jupyter в нем автоматически инициализируется ядро Python. Для того чтобы в блокноте Jupyter можно было запустить ядро Julia в Julia надо установить пакет IJulia.jl (`julia>] add IJulia`) и затем импортировать его (`using IJulia`).

После этого, для запуска блокнота Jupyter из REPL, следует вызвать функцию:

```julia
julia> notebook()
```

Блокнот откроется в браузере, назначенном по умолчанию.

Можно также, если на компьютере установлен Jupyter, запускать его непосредственно. Но для того, чтобы в нём появилось ядро julia всё равно потребуется предварительная установка пакета IJulia.

Кроме того, блокнот Jupyter может быть интегрирован в VS code. Для этого потребуется скачать соответствующее рассширение VS code. Если расширение установлено, то запуск блокнота Jupyter из VS code осуществляется нажатием комбинации клавиш `Shift+Ctrl+P` и выбором соответсвующего пункта меню (котрое ниспадает при нажатии указанной комбинации). Остается только в открывшимся блокноте выбрать ядро julia.

### Блокнот Neptune

Кроме блокнотов Jupyter для языка Julia имеется альтернативная возможность использовать блокноты Neptune, идеология которых существенным образом отличается от идеологии блокнотов Jupyter.

Основное отличие состоит в том, что блокноты Neptune, в отличие от блокнотов Jupyter, отсутствуют скрытое внутреннее состояние, определяемое значениями ранее определенных переменных. Так если в блокте Neptune в некоторой ячейке определена (инициализирована) некоторая переменная, то в других ячейках этой переменной не получится присвоить другое значение (такая попытка приведет к сообщению об ошибке). А если в исходной ячейке значение этой переменной заменить на другое, то этоавтоматически приведет к перевычислению всех остальных ячеек, в которых эта переменная используется. В блокнотах Jupyter в этом отношении может возникнуть полная путаница (при неаккуратной работе).

Для знакомства с Neptune потребуется, прежде всего, установить импортировать этот пакет:

```julia
julia>] add Neptune
julia> using Neptune
```

Далее, для запуска Neptune потребуется выполнить команду:

```julia
julia> Neptune.run()
```

В результате в браузере по умолчанию откроется окно для работы с блокнотами Neptune.

При этом, чтобы вернуться к работе с REPL, понадобится в окне REPL нажать комбинацию клавишь Ctrl+C.

**В отличие от Jupyter, блокноты Neptune сохраняются в файлах с расширением .jl.

Блокноты Neptune состоят из ячеек, аналогичных ячейкам Jupyter, в которые можно помещать программный код или текст в формате Markdown.

**Замечание.** Если при работе в Neptune в тело функции вставлять `println`, обычно это требуется при отладке, то вывод на печать будет происходить не в блокнот, а в REPL. В блокнот выводится только возвращаемое функцией значение.

## Графический пакет Plots.jl

Для построения графиков имеется в языке Julia  имеется пакет [Plots](http://docs.juliaplots.org/latest/tutorial/).

После того как этот пакет будет установлен (`julia>] add Plots`) и импортирован (`using Plots`), можно будет выбрать ту или иную графическую библиотеку (`backend`). Для этого надо выполнить одну из следующих функций (из этого пакета): `pyplot()`, `gr()`, `plotly` и др. (или использовать библиотеку, заданную по умолчанию).

Функция `pyplot()` актуализирует популярную питоновскую библиотеку `matplotlib`, функция `gr()` - другую популярную графическую библиотеку `GR` (используется по умолчанию), функция `plotly()` - одноимённую графическую библиотеку языка `Javascript`. Но не зависимо от того, какой `backend` подключен, пакет `Plots` обеспечивает унифицированный интерфейс к функциям всех перечисленных библиотек, так что на программный код `julia` факт использования той или иной графической библиотеки влияния не оказывает.

В принципе, имеется еще возможность использовать библиотеку `matplotlib`, с привычным кому-то по опыту программирования в `Python` интерфейсом, но для этого придётся уже использовать другой пакет - [`PyPlot.jl`](https://github.com/JuliaPy/PyPlot.jl/blob/master/README.md), докумментация к пакету имеется в [pyplotjl.pdf](https://buildmedia.readthedocs.org/media/pdf/pyplotjl/latest/pyplotjl.pdf).

Для построения ломаной линии в пакете  `Plots` имеется функции `plot` и `plot!`. Первая из них используется для создания графического объекта (графика) - либо пустого, либо содержащего только одну ломаную линию. Например,

```julia
p=plot() 
# создан пустой графический объект p, к которому можно будет добавлять другие графики

xdata = 0:9, ydata = rand(10)
p=plot(xdata, ydata)
# p - графический объект, содержащий ломаную линию с 10 узловыми точками
```

Чтобы узнать тип переменной `p`, можно сделать следующее.

```julia
typeof(p)
Plots.Plot{Plots.GRBackend}
```

Теперь, чтобы к созданному тем или иным способом объекту `p` можно будет добавить еще одну или несколько ломаных линий. Для этого нужно уже будет воспользоваться функцией `plot!`.

Например, следующий код построит целое семейство кривых.

```julia
p=plot()
for _ in 1:5
    plot(p, 0:9, rand(10))
end
display(p) 
```

**Замечание 1.** Для того, чтобы отобразился сформированный в объекие p график, необходимо вызвать функцию display(p).

При выполнении команды типа plot(x,y) непосредственно в REPL, при условии что эта команда была последней (или единственной), функция display будет вызывана автоматически, получив в качестве аргумента ссылку на обект с графиком, возвращаемую в данном случае функцией plot.

Однако если имеется цикл, в котором вызывалась функция plot, то графики отображены не будут (автоматически), поскольку значение цикла есть nothing. Поэтому в этом слусае необходим явный вызов функции display.

**Замечание 2.** Если в программе иммется только одно окно с графиком, то это окно всегда будет **текшим** окном (графиком). И в этом случае создавать переменную p необходимости нет, программа будет работать с текущим окном, например, прежний код мог бы быть записан еще и следующим образом.

```julia
plot()
for _ in 1:5
    plot(0:9, rand(10))
end
display() 
```

Результат получится в точности тот же.

Аналогичная ситуация может возникнуть при помещении процедуры построения графика в функцию.

Например, если имеется следующая функция

```julia

function rand_curve(n)
    x = rand(n)
    y = rand(n)
    plot(x,y)
end
```

то в результате её вызова

```julia
julia> rand_curve(100)
```

график так же будет отображаться автоматически (потому что функция вернула значение, возвращаемое функцией plot).

Но если функцию определить чуть иначе следующим образом

```julia
function rand_curve(n)
    x = 0:n-1
    y = rand(n)
    plot(x,y)
    return y
end
```

то её вызов

```julia
julia> rand_curve(100)
```

уже не приведеь к отображению графика, потому что в этом случае будет отсутствовать ссылка на объект с графиком.

Ситуацию можно было бы поправить, например, так

```julia
function rand_curve(n)
    x = 0:n-1
    y = rand(n)
    p = plot(x,y)
    return p, y
end
```

Теперь, наша функция уже будет возвращать ссылку на объект с графиком, который можно будет отобразить следующим образом.

```julia
julia> p,y = rand_curve(100)
julia> display(p)
```

Или можно было бы сделать так

```julia
function rand_curve(n)
    x = 0:n-1
    y = rand(n)
    plot(x,y)
    display()
    return y
end
```

Но в общем случае такой вариант представляется не очень хорошим решением. Лучше когда функции только что-либо вычисляют, а соответствующие графики уже можно будет будет построить на самом верхнем уровне, т.е. непосредственно в REPL.

Во всех приведенных выше примерах свойства линий графика устанавливаются автоматически (значениями, принятыми по умолчанию), причем цвета графиков автоматически задаются так, чтобы разные линии различались по цвету.

Для того, чтобы свойства графика (`Series Attributes`): цвет линии (`linecolor`), толщина линии (`linewidth`), стиль линии (`linestyle`), размер узловых точек (`markersize`), их цвет (`markercolor`), их форма (`markershape`) и т.п. можно было задавать требуемым образом, у функций `plot`, `plot!`, `skatter`, `skatter!` предусмотрены соответствующие именованные аргументы.

Так, атрибуты линии графика `linecolor` и `markercolor` задается символьными значениями, такими как `:red` (красный), `:green` (зеленый), `:blue (голубой)`, `:violent (фиолетовый)`, `:yellow` (желтый) `:grey` (серый), `:white` (белый), `:black` (чёрный) и др., вот полный перечень наименований в системе цветов [X11](https://en.wikipedia.org/wiki/X11_color_names). Значение цвета также можно задавать с помощью конструктора цвета `RGB(r, g, b)`, где параметры `r`,`g`,`b` со значеями из отрезка $[0;1]$ опеределяют интенсивность соответсвующих составляющих цвета.

Атрибут `linestyle` - определяет стиль линии, он задается символьным значением из числа:  `:auto`, `:solid` (сплошная линия), `:dash` (пунктир), `:dot` (точки), `:dashdot` (штрих-пунктир), `:dashdotdot` (двойной штрих-пунктир).

Атрибут `markershape` - определяет форму маркера, он задается символьным значением из числа: `:circle`, `:cross`, `:xcross` и др.

Aтрибут `seriestype` - определяет тип графика, он задается символьным значением из числа: `:line` (строится обычная ломаная),  `:scatter` (строятся только узловые точки графика, не соединенные линиями), `:shape` (строится многоугольник с заливкой цветом) и др. (предусмотрены ещё многие другие типы графиков).

Например, чтобы построить график многоугольника, залитого цветом, координаты вершин котрого содержатся в двух числовых массивах `xdata`, `ydata`, можно воспользоваться значением `:shape` фтрибута `seriestype`:

```julia
plot(xdata, ydata; seriestype = :shape, color = RGB(1,0,0)) # RGB(1,0,0) - это тоже самое, что и :red (красный)
```

Также иожно пользоваться конструктором специального типа `Shape`:

```julia
plot(Shape(xdata, ydata); color = :red)
```

Особенно удобно пользоватся этим конструктором, если координаты вершин многоугольника заданы не двумя отдельными числовыми массивами, а одним массивом кортежей пар вещественных чисел: `verdata::Vector{Tuple{Real, Real}}`:

```julia
plot(Shape(verdata); сolor = RGB(0,1,0))
```

**Замечание 3.** Если имеются числовые массивы `xdata`, `ydata`, то построить из них массив кортежей можно с помощью ыстроенной функции `zip` (возвращающей генератор соответствующих кортежей): `verdata=[p for p in zip(xdata, ydata)]`.

Aтрибут `aspect_ratio` (или просто `ratio`) - определяет масштабы на координатных осях, он задается символьными значениями: `:auto` (масштабы выбираются автоматически), `:equal` (масштабы устанавливаются одинаковыми) и др.

Атрибуты `linewidth`, `markersize` - задаются числовыми значениям (нужные величины можно подобрать эксперментально).

Кроме функций `plot` и `plot!`  в пакете имеются ещё функции `scatter` и, соответственно, `scatter!`. Вместо двух последних можно использовать также функции `plot` и `plot!`, вызываемые с нужным значением соответсвующего  именованного параметра `seriestype = :scatter`, имеющегося у них.

Более подробную информацию о функциях пакета Plots можно найти [здесь](http://docs.juliaplots.org/latest/tutorial/).

# Лекция 7. Генерация комбинаторных объектов

- Размещения `n` элементов по `k` с повторениями.
- Перестановки `n` элементов.
- Все подмножества `n`-элементного множества.
- `k`-элементные подмножества `n`-элементного множества.
- Разбиения натурального числа на положительные слагаемые.
- Итераторы для перебора комбинаторных объектов.

## 1. Генерация всех размещений с повторениями из n элементов {1,2,...,n} по k

Требуется перечислить все возможные последовательности длины k, элементы которых принадлежат `{1,2,...,n}`.
Идея состоит в том, чтобы перечисоить их в **лексикографическом** порядке.

Говорят, что строки (кортежи, вектора) $s_1,s_2,s_3...$ перечислены в лексикографическом порядке, если $\forall i \ s_i<s_{i+1}$, что означает, что либо $s_{i}$ короче $s_{i+1}$ и $s_i$ совпадает с началом $s_{i+1}$, либо первые $m \ (m \ge 0)$ элементов в $s_i$ и $s_{i+1}$ совпадают, и $s_{i}[m+1] < s_{i+1}[m+1]$.

Таким образом, перечислить все вектора длины k требуется в таком порядке: 

[1,...,1,1]

[1,...,1,2]

...........

[1,...,1,n]

[1,...,2,1]

[1,...,2,2]

...........

[1,...,2,n]

[1,...,3,1]

...........

[1,...,3,n]

...........

[n,...,n,n]

В частности, при n=2 и k=3, имеем 2^3=8 размещений с повторениями:

[1, 1, 1]

[1, 1, 2]

[1, 2, 1]

[1, 2, 2]

[2, 1, 1]

[2, 1, 2]

[2, 2, 1]

[2, 2, 2]

Напишем функцию, котрая получив на вход какой-либо вектор длины k, с элементами из {1,2,...,n}, возвращает "следующий" вектор.

```julia
function next_repit_plasement!(p::Vector{T}, n::T) where T<:Integer
    i = findlast(x->(x<n), p) # используется встроенная функция высшего порядка
    if isnothing(i)
        # p - это самый последний вектор в последовательности, следующего уже нет
        return nothing
    end
    p[i] += 1
    p[i+1:end] .= 1 # - устанавливаются минимально-возможные значения
    return p
end
```

Протестировать эту функцию можно, например, так:

```julia
n = 2; k = 3
p = ones(Int,k)
while !isnothing(p)
    global p = next_repit_plasement!(p,n)
    println(p)
end
```

**Замечание**. Вместо множества $\{1,2,...,n\}$, можно было бы рассмотривать множество $\{0,1,2,...,n-1\}$.
Тогда все размещения элементов этого множества по $k$ элементов суть $n$-ичные записи чисел $\{0,1,...,n^k-1\}$ длины $k$. 

Таким образом, все размещения элементов множества $\{0,1,2,...,n-1\}$ по $k$ элементов, могут быть перечислены с использованием встроенной функции `digits`: 

```julia
for i in 0:n^k-1
    digits(Int, i; base=n, pad=k) |> println
end
```

**Замечание.** Функция `digits` преобразует целое число `i` в вектор, составленный из последовательности цифр этого числа (это значения типа `Int`) в `n`-ичной системе счисления. Возвращаемая последовательность цифр (в виде вектора) начнается с цифры младшего разряда, причем длина этой последовательнотси больше или равна `k` (длина меньше `k` получиться не может, т.к. при необходимости недостающие цифры старших разрядов автоматически обнуляются).

С учетом этого получается, что в записанном цикле выводимые размещения будут следовать в **антилексикографическом** порядке.

## 2. Генерация вcех перестановок 1,2,...,n

Как известо существует ровно $n!$ различных перестановок n элементов.

Эти перестановки также можно перечислить в лексикографическом порядке:

[1, 2, ..., n-1, n]

...................

[n, n-1, ..., 2, 1]

В частности, при n = 4 имеем 4!=24 перестановки:

[1, 2, 3, 4]

[1, 2, 4, 3]

[1, 3, 2, 4]

[1, 3, 4, 2]

[1, 4, 2, 3]

[1, 4, 3, 2]

[2, 1, 3, 4]

[2, 1, 4, 3]

[2, 3, 1, 4]

[2, 3, 4, 1]

[2, 4, 1, 3]

[2, 4, 3, 1]

[3, 1, 2, 4]

[3, 1, 4, 2]

[3, 2, 1, 4]

[3, 2, 4, 1]

[3, 4, 1, 2]

[3, 4, 2, 1]

[4, 1, 2, 3]

[4, 1, 3, 2]

[4, 2, 1, 3]

[4, 2, 3, 1]

[4, 3, 1, 2]

[4, 3, 2, 1]

Таким образом, для того, чтобы из заданной перестановки получить "следующую", требуется:

- перемещаясь из конца перестановки p к её началу, найти ближайшую позицию k, на которой k+1-ый элемент больше k-го. Причем, если такой позиции не окажется (в этом случае будем считать k=0), то это означает, что данная перестановка является "последней". Т.е., если только перестановка p не является "последней", имеем 
`p[k]<p[k+1] > p[k+2]>...>p[n]`
- затем, в "хвосте" `p[k+1:n]` надо найти позицию `i`, на которой стоит наименьшее значение, большее `p[k]`;
- затем, элементы  `p[k]` и `p[i]` требуется поменять местами, а все элементы `p[i+1]...p[n]` переставить в обратном порядке.

Соответствующий программный код, может выглядеть следующим образом.

```julia
function next_permute!(p::AbstractVector)
    n = length(p)
    k = 0 # или firstindex(p)-1
    for i in reverse(1:n-1) # или reverse(firstindex(p):lastindex(p)-1)
        if p[i] < p[i+1]
            k=i
            break
        end
    end
    k == firstindex(p)-1 &&  return nothing # т.е. p[begin]>p[begin+1]>...>p[end]
 
    #УТВ: p[k]<p[k+1] > p[k+2]>...>p[end]
    i=k+1
    while i<n && p[i+1]>p[k] # i < lastindex(p) && p[i+1] > p[k]
        i += 1
    end
    #УТВ: p[i] - наименьшее из всех p[k+1:end], большее p[k]
    p[k], p[i] = p[i], p[k]
    #УТВ: по-прежнему p[k+1]>...>p[end]
    reverse!(@view p[k+1:end])
    return p
end

#Тестирование:
p=[1,2,3,4]
while !isnothing(p)
    println(p)
    global p
    p = next_permute!(p)
    println(p)
end
```

## 3. Генерация всех всех подмножеств n-элементного множества {1,2,...,n}

**Индикатором** (индикаторной функцией) некоторого множества $B$ называется функция, определенная на соответствующем **универсальном** для данной задачи множестве $A$ ($B \subset A$) следующим образом:

$$
I_B(x) =
\begin{cases}
1, & \text{если } x \in B\\
0, & \text{если } x \notin B
\end{cases}
$$

Здесь значения `1`, `0` можно интерпретировать как `true` и `false`, соответственно.

В частности, если "универсальное" множество $A$ представлено вектором $[1,2,...,n]$, то индикаторную функцию $I_B$ любого его подмножества $B$, можно представить одноименным массивом булевского типа (`Bool`): `I_B[i] = true`, если `A[i] in B`, то , и `I_B[i] = false` - в противном случае.

Таким образом, задача перечисления всех подмножеств `B` заданного множества `A` фактически сводится к перечислению их индикаторов.

Индикаторы всех подмножеств множества $A=\{1,2,...,n\}$ будем перечислять в лексикографическом порядке:

[0, 0, ..., 0, 0]

[0, 0, ..., 0, 1]

.................

[1, 1, ..., 1, 0]

[1, 1, ..., 1, 1]

Рассмотрим два способа перечеслиния этих индикаторов.

### 3.1. Первый способ - на основе генерации двоичных кодов чисел 0, 1, ..., 2^n-1

```julia
indicator(i::Integer, n::Integer) = digits(Bool, i; base=2, pad=n) # reverse(digits(Bool, i; base=2, pad=n))
```

**Замечание.** Функция `digits` возвращает последовательность цифр в обратном порядке, поэтому, чтобы получать с её помощью соответствующие вектора именно в лексикографическом порядке, их нужно было бы переворачивать. Однако этого делать не обязательно, важно лишь, чтобы были перечислены все индикаторы.

### 3.2. Второй способ - на основе непосредственной генерации последовательности индикаторов в лексикографическом порядке

Процедура состоит в следующем:

- надо найти индекс самого последнего нулевогоэлемента масства (индикатора); если такогого не найдется, то данный вектор есть индикатор всего множества и, следовательн, является "последним";

- затем этому элементу следует присвоить значение 1, а все последующие - обнулить.

Соответствующий программный код может быть записан следующим образом.

```julia
function next_indicator!(indicator::AbstractVector{Bool})
    i = findlast(x->(x==0), indicator)
    isnothing(i) && return nothing
    indicator[i] = 1
    indicator[i+1:end] .= 0
    return indicator 
end
```

Протестировать эту функцию можно так:

```julia
n=5; A=1:n
indicator = zeros(Bool, n)
while !isnothing(indicator)
    global indic
    A[findall(indicator)] |> println
    indicator = next_indicator!(indicator)
    println(indicator)
end
```

## 4. Генерация всех k-элементных подмножеств n-элементного множества {1, 2, ..., n}

Это задачу можно было бы решать на основе перечисления всех подмножеств и выбора из них только $k$-элементных, однако это было бы не эффективно, поскольку число всех подмножеств $n$-элементного множества есть равно $2^n$.

Поэтому будем перечислять эти индикаторы в лексикографическом порядке непосредственно:

[0, ..., 0, 1, ..., 1] - все k единиц - в самом конце

......................

[1, ..., 1, 0, ..., 0] - все k единиц - в самом начле

Например, при $n=6, k=3$, имееем всего $C_n^k=\frac{6!}{3!\cdot 3!}=20$ подмножеств:

[0, 0, 0, 1, 1, 1]

[0, 0, 1, 0, 1, 1]

[0, 0, 1, 1, 0, 1]

[0, 0, 1, 1, 1, 0]

[0, 1, 0, 0, 1, 1]

[0, 1, 0, 1, 0, 1]

[0, 1, 0, 1, 1, 0]

[0, 1, 1, 0, 0, 1]

[0, 1, 1, 0, 1, 0]

[0, 1, 1, 1, 0, 0]

[1, 0, 0, 0, 1, 1]

[1, 0, 0, 1, 0, 1]

[1, 0, 0, 1, 1, 0]

[1, 0, 1, 0, 0, 1]

[1, 0, 1, 0, 1, 0]

[1, 0, 1, 1, 0, 0]

[1, 1, 0, 0, 0, 1]

[1, 1, 0, 0, 1, 0]

[1, 1, 0, 1, 0, 0]

[1, 1, 1, 0, 0, 0]

Таким образом, процедура состоит в следующем:
- двигаясь с конца массива к его началу ищем первый элемент, который можно увеличить (первый элемент, равный 0, за которым стоит 1);
- увеличиваем его, т.е. заменяем 1, а остальные элементы в "хвосте" определяем "минимально возможным" способом, т.е. все содержашиеся в нем единицы "перемещаем" в саымый конец.

```julia
function next_indicator!(indicator::AbstractVector{Bool}, k)
    # в indicator - ровно k единц, остальные - нули, но это не проверяется! (фактически k - не используется)
    i=lastindex(indicator)
    while indicator[i]==0
        i-=1
    end
    #УТВ: indic[i]==1 и все справа - нули
    m=0; 
    while i >= firstindex(indicator) && indicator[i]==1 
        m+=1
        i-=1
    end
    if i < firstindex(indicator)
        return nothing
    end
    #УТВ: indicator[i]==0 и справа m>0 единиц, причем indicator[i+1]==1
    indicator[i]=1
    indicator[i+1:i+m-1] .= 0
    indicator[i+m:end] .= 1
    return indicator 
end
```

Протестировать эту функцию можно, например, следующим образом.

```julia
n=6; k=3; A=1:n
indicator = [zeros(Bool,n-k); ones(Bool,k)]
A[findall(indicator)] |> println
for !isnothing(indicator)
    global indicator = next_indicator!(indicator, k)
    A[findall(indicator)] |> println
end
```

## 5. Генерация всех разбиений натурального числа на положительные слагаемые

Дано натуральное (неотрицательное целое) число n. Тпебуется найти все возможные представления (разбиения) этого числа в виде суммы натуральных чисел. При этом разбиения, отличающиеся только порядком слагаемых, не будем считать разными.

Рассмотрим пример при n=5:

 `5 = 1+1+1+1+1 = 2+1+1+1+0 = 2+2+1+0+0 = 3+1+1+0+0 = 3+2+0+0+0 = 4+1+0+0+0 = 5+0+0+0+0`


Идея процедуры перечисления всех разбиений состоит в том, чтобы перечислить их в лексикографическом порядке. При этом число ненулевых элементов каждого последующего разбиения не будет превосходить числа ненулевых элементов данного разбиения.

Для этого все ненулевые слагаемые, входящие в какое-либо разбиение, будем хранить в векторе `s`, при этом: 

- `n = s[1]+...+s[k]`, где `k=length(s)` - число положительных слагаемых в разбиении;
- дополнительно потребуем чтобы `s[i-1]>=s[i]` при всех `i in (2,3,...,k)` (чтобы исключать разбиения, отличающиеся лишь порядком элементов).

Тогда, чтобы при выполнении этих двух условий можно было бы увеличить `s[i]`, не меняя значений `s[1],...,s[i-1]`, 
требуется, чтобы
- `s[i-1] > s[i]` или `i = 1`
- `i < k` (что бы иметь возможность уменьшения последуюших элементов, для сохранения требуемого баланса).

При увеличении значения `s[i]` на `1`, все последующие элементы надо брать минимально возможными (в лесикографическом смысле).

```julia
"""
Должно быть length(s) == n, где n - заданное число
    
    s[i-1]>=s[i] for all i in (2,3,...,k), 

где k - число элементов заданного разбиения, представленного вектором s, т.е. число ненулевых элементов в начале вектора s.
"""
function next_split!(s::AbstractVector{Integer}, k)
    k == 1 && return nothing
    i = k-1 # - это потому что s[k] увеличивать нельзя
    while i > 1 && s[i-1]==s[i]
        i -= 1
    end
    #УТВ: i == 1 или i - это наименьший индекс: s[i-1] > s[i] и i < k
    s[i] += 1
    #Теперь требуется s[i+1]... - уменьшить минимально-возможным способом (в лексикографическом смысле) 
    r = sum(@view s[i+1:k])
    k = i+r-1 # - это с учетом s[i] += 1
    s[i+1:n-k] .= 1
    return s, k
end

# Тестирование:
n=5; s=ones(Int, n); k=n
while !isnothing(s)
    println(s[1:k])
    global s
    s, k = next_split!(s, k)
    println(s)
end
```

## 6. Специальные пользовательские типы и итераторы для генерации рассматриваемых комбинаторных объектов

Мы разработали следующие функции

`next_rep_plasement(c::Vector, n)` - для генерации размещений с повторениями
`next_permute(p::AbstractVector)`  - для генерации перестановок
`next_indicator(indicator::AbstractVector{Bool})` - для генерации всех подмножеств
`next_indicator(indicator::AbstractVector{Bool}, k)` - для генерации k-элементных подмножеств
`next_split(s::AbstractVector{Integer}, k)` - для генерации разбиений

Все эти функции предполагается использовать так: сначала создается некоторый начальный комбинаторный объект, а затем в цикле, с помощью какой-либо из перечисленных функций, получаются все остальные комбинаторные объекты до тех пор, пока перечисление этих объектов не будет исчерпано.

Однако такие перечисления объектов можно организовывать с помощью итераторов, что делает код более "чистым". Но для этого для каждого класса комбинаторных объетов понадобится спроектировать соответствующий пользовательский тип, для которго также потребуется определить функцию `iterate`. 

При этом, поскольку каждый из рассматриваемых нами комбинаторных объектов представляется просто некоторым числовым вектором, которые мы собираемся "обернуть" в соответствующую структуру, все итераторы для таких типов не будут различаться, то представляется целесообразным сначала определить следующий абстрактный тип. От которого затем будут наследовать все интересующие нас конкретные типы.

```julia
abstract type AbstractCombinObject
    # value::Vector{Int} - это поле предполагается у всех конкретных типов, наследующих от данного типа
end

Base.iterate(obj::AbstractCombinObject) = (get(obj), nothing)
Base.iterate(obj::AbstractCombinObject, state) = 
    if isnothing(next!(obj)) # == false
        nothing
    else
        (get(obj), nothing)
    end
```

В этом определении абстрактного типа предполагается, что в каждом производном от него конкретном типе будет наличествовать:

- специальное поле, в котором будет храниться значение, определяющее очередной комбинаторный объект, и функция `get`, возвращающее значение этого объекта;
  
- функция `next!`, получающая на вход некоторый комбинаторный объект соответствующего конкретного типа и изменяющая его так, что бы содержащееся в нем значение стало "следущим".

Далее будут определены требуемые производные конкретные типы.

### 6.1. Размещения с повторениями

```julia
struct RepitPlacement{N,K} <: AbstractCombinObject
    value::Vector{Int}
end

RepitPlacement{N,K}() where {N, K} = RepitPlacement{N,K}(ones(Int, K))
Base.get(p::RepitPlacement) = p.value
next!(p::RepitPlacement{N,K}) where {N, K} = next_repit_plasement!(p.value, N)

# Тестирование:
for a in RepitPlasement{2,3}() 
    println(a)
end
# такая запись стала возможной благодаря определению функции iterate(::AbstractCombinObject)
```

## 6.2. Перестановки

```julia
struct Permute{N} <: AbstractCombinObject
    value:Vector{Int}
end

Permute{N}() where N = Permute{N}(collect(1:N))
Base.get(obj::Permute) = obj.value
next!(permute::Permute) = next_permute!(permute.value)

# Тест:
for p in Permute{4}()
    println(p)
end
```

### 6.3. Все подмножества n-элементного множества

```julia
struct Subset{M} <: AbstractCombinObject # M::Union{Set, Vector, Tuple}
    indicator::Vector{Bool}
end

Subset{M}() where M = Subset{M}(zeros(Bool, length(M)))
Base.get(sub::Subsets{M}) where M = collect(M)[findall(sub.indicator)]

next!(sub::Subset{M}) where M = next_indicator!(sub.indicator) 
#=
Можно было бы возвращать:
    Subset{collect(M)[next_indicator!(sub.indicator)]}()
но поскольку использование функции next!  напрямую не предполагается, то преобразование индикатора в соответствующее подмножество тут не требуется
=#

#Тест:
for sub in Subset{1:4}()
    println(sub)
end
```

### 6.4. k-элементные подмоножества n-элементного множества

```julia
struct KSubset{M,K} <: AbstractCombinObject
    indicator::Vector{Bool}
end

KSubset{M, K}() where{M, K} = KSubset{M,K}([zeros(Bool, length(M)-K); ones(Bool, K)])
Base.get(sub::Subsets{M}) where M = collect(M)[findall(sub.indicator)]
next!(sub::KSubset{M, K}) where{M, K} = next_indicator!(sub.indicator, K) 

#=
параметр M - это или некоторое множество (Set) или диапазон (<:AbstractRange), представляющий множество, подмножества коророго перечисляются

параметр K - это число элементов в перечисляемых подмножествах
=#

#Тест:
for sub in KSubset{1:6, 3}()
    sub |> println
end
```

### 6.5. Разбиения

```julia
struct NSplit{N} <: AbstractCombinObject
    value::Vector{Int}
    num_terms::Int # число слагаемых (это число мы обозначали - k)
end

NSplit{N}() where N = NumSplit{N}(collect(1:N), N)
Base.get(nsplit::NSplit) = nsplit.value[begin:nsplit.num_terms]
next!(nsplit::NSplit) = next_solit!(nsplit.value, nsplit.num_terms)

# Тест:
for s in NSplit{5}()
    println(s)
end
```

# Лекция 8
- Представление множества упорядоченными двоичными деревьями
- Представление множества с помощью хеширования (встроенный тип данных Set)
- Хеш-таблицы (ассоциативные массивы, словари, встроенный тип данных Dict)
- Очередь с приоритетом
- Куча
- Пирамидальная сортировка
- Жадные алгоритмы
- Алгоритмы построения остова наименьшего веса для заданного взвешенного неориентированного графа
- Примеры задач, не решаемых жадными алгоритмами (задача коммивояжера, задача о рюкзаке)
- Динамическое программирование

## Множество, как структура данных

Операции:

- in
- push!
- pop!

- intersect
- union
- setdiff


### **Способы представления множества**

- на базе простого массива:
    - in - $O(N)$
    - push! - $O(N)$ (сначала требуется найти свободную позицию)
    - pop! - $O(N)$
- на базе отсортированного массива:
    - in - $O(\log N)$ (возможен быстрый поиск)
    - push! - $O(N)$ (приходится смещать элементы, для освобождения позиции)
    - pop! - $O(N)$  (приходится смещать элементы)
- в виде упорядоченного двоичного дерева:
    - in - $O(\log N)$ (возможен быстрый поиск)
    - push! - $O(\log N)$ (АВЛ - деревья, красно-черные деревья)
    - pop! - $O(\log N)$  (АВЛ - деревья, красно-черные деревья)
- с помощью "хеширования" 
    - in - $O(1)$
    - push! - $O(1)$ 
    - pop! - $O(1)$

### **Хеширование**
(https://habr.com/ru/company/otus/blog/495032/)

Ранее в СССР вместо слова "хеширование" (`hash`) использовался термин "расстановка".

Идея состоит в том, чтобы элементы множества хранить в виде простого массива, но чтобы, при этом, иметь возможность каким-либо образом индекс элемента этого массива **вычислять** по значению элемента массива. Причем сложность вычисления индекса не должна зависеть от размера массива, т.е. оцениваться как $O(N)$.

Тогда, если имеется возможность быстро вычислять индекс элемента по его значению, то сложность операции `in` будет оцениваться как $O(1)$. В самом деле, вычислив по заданному значению его индекс (за $O(1)$ элементарных операций), останется только проверить, что стоит, и стоит ли, что-нибудь в массиве на соответствующей позиции, на что потребуется еще $O(1)$ операций. 

Это, может быть, на первый взгляд выглядит фантастически, однако может быть реализовано с помощью так называемых хеш-функций.

**Хеш-функция** осуществляет преобразование массива входных данных произвольной длины в выходную битовую строку установленной длины по специальному алгоритму.

Само это преобразование, осушествляемое хеш-функцией, называется **хешированием**.

Хеш-функция получает исходные данные в виде входного массива, называемые также «ключом» или «сообщением». Возвращаемый ею двоичный код фиксированной длины (т.е. некоторое неотрицательное целое число) называется «хешем», «хеш-кодом».

При этом возможно, различным значениям ключа (различным входным данным) хеш-функция будет сопоставлять одно и то же число. Такая ситуация называется **коллизией** (ранее в CCCР это называли конфликтом). Важно, чтобы хеш-функция была устроена так, чтобы коллизии возникали редко. 

#### **Борьба с коллизиями**

Массив, представляющий множество, может хранить, например, не значения элементов, а ссылки на на начала связных списков, содержащих значения, имеющие один и тот же хеш-код.

Имеется и другой способ, называемый способом разрешения коллизий с открытой индексаций. Он состоит в том, что при вставке нового элемента, если в позиции, соответствующей его хеш-коду уже имеется другое значение, то ищется ближайшая пустая "ячейка" с большим индексом (при этом массив считается "закольцованным", т.е. "больший" индекс на самом деле не обязательно будет больше). При проверке же наличия в множестве некоторого значения, сначала это значение проверятся на "своей" позиции, и если оно не совпадает с имеющемся там элементом, то проверяются все позиции с "большими" индексами, пока не будет найдено искомое значение, или пока очередная ячейка массива не окажется пустой (последнее будет означать отсутствие такого элемента).

В результате **в среднем** сложность операций `in`, `push!`, `pop!` будет иметь оценку $O(1)$ (но для наихудшего случая будет - $O(N)$).

#### **Способы реализации хеш-функций**
(https://ru.wikipedia.org/wiki/Хеш-функция)

Существует много разных способов реализации хеш-функций. 

Общие требования к хеш-функции состоят в том, что бы 
 1) она вычислялась быстро, за $O(1)$ элементарныых операций;
 2) на случайных данных её значения "равномерно" распределялись по диапазону всех возможных значений; это будет способствовать уменьшению числа возникновения коллизий.

Следующие способы хеширования рассмотрены просто для примера.

1. Способ, основанный на делении целых чисел

```julia
hesh(key::Integer, m::Integer) = key % m
```
Здесь целое число `key` представляет входные данные (последовательность каких-либо битов), `m` - это число всех возможных хеш-кодов. При этом, чтобы коллизии случались относительно редко, требуется чтобы число `m` было простым.

2. Способ, основанный на умножении на число и сдвиге

```julia
#A,n - некоторые заданные целые положительные числа (параметры)
h(key::Integer) = (A*key) >> n
```

Можно подобрать такие значения параметров A и n, чтобы хеш-функция обладала требуемыми свойствами.

3. Хеш-функция Пирсона

```julia
using Random
const PERM_TABLE = randperm(256) .- 1 # - некоторая произвольная перестановка 0-255

"""
    hesh(bayt_vector::Vector{Int8})

Преобразует любую последовательность байтов в 8-битный числовой код 
(всего имеется ровно 2^8 = 256 различных 8-битных кодов)
"""
function hesh(bayt_vector::Vector{Int8})
    h = 0
    for bayt in bayt_vector
        h = PERM_TABLE[h ⊻ bayt] # операция ⊻ - это "исключающее или" (\xor <Tab>)
    end
    return h
end

"""
    hesh(bayt_vector::Vector{Int8}, dim::Integer)

Преобразует любую последовательность байтов в вектор длины dim 8-битных числовых кодов
(всего таких различных векторов имеется ровно 2^(8*dim))
"""
function hesh(bayt_vector::Vector{Int8}, dim::Integer)
    h_vector = Vector{Int8}(undef, len)
    for j in 1:dim 
        h = PERM_TABLE[(bayt_vector[1] + j-1) % 256]
        for bayt in @view(bayt_vector[2:end]) 
            h = PERM_TABLE[h ⊻ bayt]
        end
        h_vector[j] = h
    end
    return h_vector
end
```

**Замечание.** В языке Julia имеется встроенная функция Base.heap.

## Встроенные типы данных Set, Dict

Массивы типа Set основаны на использовании хеширования.

Словари (ассоциативные массивы) типа Dict представляют собой наборы пар ключ-значение, в которых ключи хешируются. Поэтому в словаре (как и в множестве типа Set) поиск значения по его ключу осуществляется за $O(1)$ элементарных операций. Такие структуры также называются хеш-таблицами.

## Очередь с приоритетом

Операции с приоритетной очередью:
- создать пустую проритетную очередь;
- проверить, является ли в приоритетная очередь пустой;

- добавить новый элемент в приоритетную очередь;
- извлечь элемент с наивысшим приоритетом;
- увеличить/уменьшить приоритет некоторого элемента очереди.


Способы реализации приоритетной очереди:

- на базе простого массива: время добавления - $O(1)$, время извлечения - $O(N)$;
- на базе отсортированного массива: время добавления - $O(N)$, время извлечения - $O(1)$;
- с помощью "кучи": время добавления - $O(log(N))$, время извлечения - $O(log(N))$.

## Тип данных "куча"

**Куча** представляет собой двоичную иерархическую структуру, в которой значение каждого из двух дочерних элементов меньше (больше) значения родительского элемента.

Если на вершине кучи находится максимальное значение, то она называется максимальной. 

В противном случае, есле на вершине кучи находится минимальное значение, то она называется минимальной.

### Реализация кучи на базе массива

Как правило кучу реализуют на базе обычного массива.

Массив `heap` имеет структуру **кучи** (**максимальной** кучи), если  для каждого его `i`-го элемента выполнены следующие два условия:
- `heap[i] < heap[2i]`
- `heap[i] < heap[2i+1]`

разумеется, индекс `i` здесь не должен превосходить `length(heap)÷2`. 

Преобразовать произвольный массива в максимальную кучу можно за $O(N)$ действий.

```julia
function heap!(array)
    N = length(array)
    for i in 1:N÷2
        if array[i] < array[2i]
            array[i], array[2i] = array[2i], array[i]
        end
        
        if 2i+1 <= N && array[i] < array[2i+1]
            array[i], array[2i+1] = array[2i+1], array[i]
        end
    end
    return array
end
```

Соответсвенно, если при всех возможных `i` выполняются условия
 - `heap[i] > heap[2i]`
 - `heap[i] > heap[2i+1]`
 
то массив `heap` имеет структуру **минимальной** кучи.

### Перемещение элемента на место, соответствующее его приоритету

Допустим, что имеется только один единственный элемент в куче, который стоит на позиции (`i-`ой), не соответствующей его приоритету. 

Такая ситуация может возникать, например, при добавлении/удалинии элемента в кучу. А также, если при решении какой-либо задачи, на каком-то шаге произошло изменение значения приоритета какого-то одного элемента кучи. 

Задача состоит в том, что бы переместить этот элемент на нужную позицию, восстановив требуемую структуру кучи.

Это можно делать с помощью одной из следующих двух функций, сложность каждой из которых оценивается как $O(log(N))$.

```julia
"""
    up!(heap::AbstractVector, index)

"Поднимает" элемент с индексом index к вершине куче, пока этот элемент не займет свое "правильное" место в куче, и возвращает наименьший из индексов всех перемещенных при этом элементов кучи.
"""
function up!(heap::AbstractVector, index)
    @assert i <= length(heap)
    is_ord = false
    while index > 1 && is_ord == false
        is_ord = true
        if heap[index] > heap[index÷2]
            heap[index], heap[index÷2] = heap[index÷2], heap[index]
            is_ord = false
        end

        if heap[index] > heap[(index-1)÷2]
            heap[index], heap[(index-1)÷2] = heap[(index-1)÷2], heap[index]
            is_ord = false
        end     
        
        current_index = index
        if isodd(i)
            index ÷= 2
        else
            index = (index-1)÷2
        end
    end
    return current_index
end

"""
    down!(heap::AbstractVector, index)::Nothing

"Опускает" элемент с индексом index ближе к концу кучи, пока этот элемент не займет свое "правильное" место в куче.
"""
function down!(heap::AbstractVector, index)::Nothing
    N = length(heap)
    while index < N÷2
        if heap[index] < heap[2index]
            heap[index], heap[2index] = heap[2index], heap[index]
        end
        if 2index+1 <= N && heap[index] < heap[2index+1]
            heap[index], heap[2index+1] = heap[2index+1], heap[index]
        end
        index *= 2
    end
end
```
### Добавление/извлечение элементов из кучи

Если масссив heap есть минимальная куча, то добавить в нее новый элемент (сохраняя структуру кучи) можно за `O((log N))` действий следующим образом.

```julia
"""
    push!(heap::AbstractVector, new_elem)::Nothing

Добавляет новый элемент в кучу, представленную массивом.
"""
function Base.push!(heap::AbstractVector, new_elem)::Nothing
    push!(heap, new_elem)
    up!(heap, lastindex(heap))
end

```

Соответственно, извлечь очередной (максимальный) элемент из кучи можно также за `O((log N))` действий следующим образом.

```julia
"""
    pop!(heap::AbstractVector, new_elem)

Извлекает из кучи, представленной массивом, и возвращает элемент с наивысшим приоритетом.
"""
function Base.pop!(heap::AbstractVector, new_elem)
    heap[begin], heap[end] = heap[end], heap[begin]    
    max_value = pop!(heap)
    down!(heap, firstindex(heap))
    return max_value
end

"""
dec_priority!(heap::AbstractVector{T}, index::Integer, new_value::T)::Nothing where T

Выполняет необходимое перестраивание максимальной кучи при замене heap[index] мЕньшим значением new_value.
"""
function dec_priority!(heap::AbstractVector{T}, index::Integer, new_value::T)::Nothing where T
    @assert new_value <= heap[index]
    prioity[index] = new_value
    down!(heap, index)
end

"""
inc_priority!(heap::AbstractVector{T}, index::Integer, new_value::T)::Nothing where T

Выполняет необходимое перестраивание максимальной кучи при замене heap[index] бОльшим значением new_value.
"""
function inc_priority!(heap::AbstractVector{T}, index::Integer, new_value::T)::Nothing where T
    @assert new_value >= heap[index]
    prioity[index] = new_value
    up!(heap, index)
end
```

Последние две функции, скорее всего, не будут полезными для практического использования, потому что для этого потребовалось бы уметь быстро определять номер позиции index, на которой в данный момент находтися значение приоритета, требуеющее быть замененном на другое. Но вот как именно это значение index может быть быстро определено - это пока остается под вопросом. 

В дальнейшем нами будет разработан специальный тип данных, с помощью которого эта проблема будет разрешена. 
Но не будем пока на этом состредотачиваться, сейчас важно лишь понять принципиальную возможность и механизм быстрой перестройки кучи при изменениисейчас приоритета одного из ее элементов. 

## Пирамидальная сортировка

Пусть $heap$ - произвольный вектор длины $N$.

Процедура сортировки состоит из следующих шагов.

1. Преобразуем исходный массив в кучу (с помощью функции heap!).

2. Поменяем местами первый элемент массива (после предыдущего шага он будет максималным) с последним (тем самым последний элемент массива окажется на "своем" окончательном месте), и переместим первый элемент массива на "правильное" место в куче. С использованием функции `down!` на это потребуется $O(\log N)$ элементарных операций.

4. Длину сортируемой части массива уменьшим на 1 и перейдем к пункту 2, и т.д. пока длина сортируемой части станет раной 3 (первые три элемента кучи всегда отсортированы).

Таким образом, сложность пирамидальной сортировки имеет оценку $O(N \log N)$. 

```julia
function heap_sort!(heap::AbstractVector)
    heap = heap!(heap) 
    # здесь heap! - это именно функция, преобразующая массивив в максимальную кучу, а не конструктор типа Heap!
    N = length(heap)  
    #ИНВАРИАНТ: heap[1:N] - это максимальная куча && heap[N+1:end] - это отсортированная часть массива
    while N > 3
        heap[1], heap[N] = heap[N], heap[1]
        N -= 1
        down!(@view(heap[1:N]), 1) 
        # - это вызов метода down!(::AbstractVector, Any), а не метода down!(::Heap!, ::Any)
    end
    return heap
end
```

## Пользовательский тип данных Heap!

Спроектированные нами функции `heap!`, `up!`, `down!`, `push!`,`pop!`, позволяют создать и работать с максимальной кучей, представленной обычным массивом. 

При этом, если вместо максимальной кучи потребуется минимальная куча, то будет достаточно перед началом просто в массиве поменять знаки всех элементов на противоположные. просто 

Однако есть задачи, при решении которых могут происходить изменения приоритетов отдельных элементов кучи. Тогда оказывается целесообразным в самой куче хранять не значения прироитетов, а лишь индексы массива с значениями приоритетов, а для записи самих приоритетов использовать отдельный массив, элементы которого никогда не будут перемещаться (но могут быть изменены). При этом будет необходимо установить соответствие между индексами массива приоритетов и индексами массива, представляющего собственно кучу. Для установления такого соответствия удобно будет использовать словарь типа `Dict{Int, Int}`, которая обеспечит желаемое здесь быстрое установление соответствий (за $O(1)$ элементарных операций), т.к. этот тип данных основан на хешировании. 

Т.е. пусть значение целого типа `index_priority` - это индекс какого-то элемента массива приоритетов, т.е. соответствующего ему приоритета есть `priority[index_priority]`, где `priority` - заданный массив приоритетов. 
Тогда позиция того же элемента в куче будет определена значением `index_heap[index_priority]`, где  `index_heap` - это объет словарь типа `Dict{Int, Int}`.  

Для реализации этого механизма, придется разработать специальный тип данных (структуру), который назовем `Heap!`.

```julia
"""
Heap!{:maх}(heap::AbstractVector, priority::Vector)

Приоритеты элементов массива heap определяются с помощью параметра priority.
"""
struct Heap!{T} # T = :min или Т = :max
    heap::Vector{Int}
    priority::Vector
    index_heap::Dict{Int,Int} 

    function Heap!{:maх}(priority::AbstractVector)
        @assert firstindex(priority) == 1
        heap = collect(1:length(priority))
        index_heap = Dict([i=>i for i in eachindex(priority)])   
        N=length(heap)
        for i in 1:N÷2
            if priority[heap[i]] < priority[heap[2i]] 
                heap[i], heap[2i] = heap[2i], heap[i]
                index_heap[heap[i]], index_heap[heap[2i]] = index_heap[heap[2i]], index_heap[heap[i]]
            end
        
            if 2i+1 <= N && priority[heap[i]] < priority[heap[2i+1]]
                heap[i], heap[2i+1] = heap[2i+1], heap[i]
                index_heap[heap[i]], index_heap[heap[2i+1]] = index_heap[heap[2i+1]], index_heap[heap[i]]
            end
        end
        new(heap, priority, index_heap)
    end

    function Heap!{:min}(priority::AbstractVector)
        @assert firstindex(priority) == 1
        heap = collect(1:length(priority))
        index_heap = Dict([i=>i for i in eachindex(priority)])   
        N=length(heap)
        for i in 1:N÷2
            if priority[heap[i]] > priority[heap[2i]] 
                heap[i], heap[2i] = heap[2i], heap[i]
                index_heap[heap[i]], index_heap[heap[2i]] = index_heap[heap[2i]], index_heap[heap[i]]
            end
        
            if 2i+1 <= N && priority[heap[i]] > priority[heap[2i+1]]
                heap[i], heap[2i+1] = heap[2i+1], heap[i]
                index_heap[heap[i]], index_heap[heap[2i+1]] = index_heap[heap[2i+1]], index_heap[heap[i]]
            end
        end
        new(heap, priority, index_heap)
    end
end

Base.isempty(heap::Heap!) = isempty(heap.heap)

"""
    up!(heap::Heap!, index)::Nothing

"Поднимает" элемент кучи с индексом index ближе к её вершине, пока он не займет свое "правильное" место.
"""
function up!(heap::Heap!{:max}, index)::Nothing
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    while index > 1 
        if  priority[heap[index÷2]] < priority[heap[index]]
            heap[index], heap[index÷2] = heap[index÷2], heap[index]
            index_heap[index], index_heap[index÷2] = index_heap[index÷2], index_heap[index]
        end

        if priority[heap[(index-1)÷2]] < priority[heap[index]]
            heap[index], heap[(index-1)÷2] = heap[(index-1)÷2], heap[index]
            index_heap[index], index_heap[(index-1)÷2] = index_heap[(index-1)÷2], index_heap[index]
        end     
        
        if isodd(index)
            index ÷= 2
        else
            index = (index-1)÷2
        end
    end
end

function up!(heap::Heap!{:min}, index)::Nothing
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    while index > 1 
        if  priority[heap[index÷2]] > priority[heap[index]]
            heap[index], heap[index÷2] = heap[index÷2], heap[index]
            index_heap[index], index_heap[index÷2] = index_heap[index÷2], index_heap[index]
        end

        if priority[heap[(index-1)÷2]] > priority[heap[index]]
            heap[index], heap[(index-1)÷2] = heap[(index-1)÷2], heap[index]
            index_heap[index], index_heap[(index-1)÷2] = index_heap[(index-1)÷2], index_heap[index]
        end     
        
        if isodd(index)
            index ÷= 2
        else
            index = (index-1)÷2
        end
    end
end

"""
    down!(heap::Heap!, index)::Nothing

"Опускает" элемент кучи с индексом index ближе к её концу, пока он не займет свое "правильное" место.
"""
function down!(heap::Heap!{:max}, index)::Nothing
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    N = length(heap)
    while index < N÷2
        if priority[heap[index]] < priority[heap[2index]]
            heap[index], heap[2index] = heap[2index], heap[index]
            index_heap[index], index_heap[2index] = index_heap[2index], index_heap[index]
        end
        if 2index+1 <= N && priority[heap[index]] < priority[heap[2index+1]]
            heap[index], heap[2index+1] = heap[2index+1], heap[index]
            index_heap[index], index_heap[2index+1] = index_heap[2index+1], index_heap[index]
        end
        index *= 2
    end
end

function down!(heap::Heap!{:min}, index)::Nothing
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    N = length(heap)
    while index < N÷2
        if priority[heap[index]] > priority[heap[2index]]
            heap[index], heap[2index] = heap[2index], heap[index]
            index_heap[index], index_heap[2index] = index_heap[2index], index_heap[index]
        end
        if 2index+1 <= N && priority[heap[index]] > priority[heap[2index+1]]
            heap[index], heap[2index+1] = heap[2index+1], heap[index]
            index_heap[index], index_heap[2index+1] = index_heap[2index+1], index_heap[index]
        end
        index *= 2
    end
end

"""
    push!(heap::Heap!, new_elem)::Nothing

Добавляет новый элемент в кучу.
"""
function Base.push!(heap::Heap!, new_elem)::Nothing
    heap = heap.heap
    push!(heap, new_elem)
    up!(heap, lastindex(heap))
end

"""
    pop!(heap::Heap!, new_elem)

Извлекает из кучи и возвращает элемент с наивысшим/наинизшем приоритетом.
"""
function Base.pop!(heap::Heap!, new_elem::Integer)
    heap[begin], heap[end] = heap[end], heap[begin]    
    max_value = pop!(heap.heap)
    down!(heap, firstindex(heap))
    return max_value
end

"""
    dec_priority!(heap::Heap!{:max}, index_priority::Integer, new_value)::Nothing

Выполняет необходимое перестраивание максимальной кучи при замене heap.priority[index_priority] на меньшее значение new_value.
"""
function dec_priority!(heap::Heap!{:max}, index_priority::Integer, new_value)::Nothing
    # @assert new_value <= heap.priority[index_priority]
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    priority[index_priority] = new_value
    down!(heap, index_heap[index_priority])
end

"""
    inc_priority!(heap::Heap!{:max}, index::Integer, new_value::T)::Nothing where T

Выполняет необходимое перестраивание максимальной кучи при замене heap.priority[index_priority] на большее значение new_value.
"""
function inc_priority!(heap::Heap!{:max}, index_priority::Integer, new_value)::Nothing
    # @assert new_value >= heap.priority[index_priority]
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    priority[index_priority] = new_value
    up!(heap, index_heap[index_priority])
end

"""
    dec_priority!(heap::Heap!{:min}, index_priority::Integer, new_value)::Nothing

Выполняет необходимое перестраивание минимальной кучи при замене heap.priority[index_priority] на меньшее значение new_value.
"""
function dec_priority!(heap::Heap!{:min}, index_priority::Integer, new_value)::Nothing
    # @assert new_value <>= heap.priority[index_priority]
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    priority[index_priority] = new_value
    up!(heap, index_heap[index_priority])
end

"""
    inc_priority!(heap::Heap!{:min}, index_priority::Integer, new_value)::Nothing

Выполняет необходимое перестраивание минимальной кучи при замене heap.priority[index_priority] на большее значение new_value.
"""
function inc_priority!(heap::Heap!{:min}, index_priority::Integer, new_value)::Nothing
    # @assert new_value >= heap.priority[index_priority]
    priority = heap.priority
    index_heap = heap.index_heap
    heap = heap.heap
    priority[index_priority] = new_value
    down!(heap, index_heap[index_priority])
end

Base.iterate(heap::Heap!) = iterate(heap.heap)
Base.iterate(heap::Heap!, i::Integer) = iterate(heap.heap, i)
```

**Замечание.** Для языка Julia имеется пакет DataStructures.jl, в котором определены различные структуры данных, в том числе и куча.

## Задача построения остова наименьшего веса для заданного неориентированного взвешенного графа

https://ru.wikipedia.org/wiki/Минимальное_остовное_дерево

Это пример задачи, решаемой "жадным" алгоритмом.

### Алгоритм Прима

Шаги алгоритма.

1. Возьмем произвольную вершину, и из всех инцидентных ей ребер выберем имеющее наименьший вес. Это ребро войдет в искомый остов.

2. Проделаем аналогичную процедуру, в которой будут участывовать уже две вершины ребра, выбранного на предыдущем шаге. В результате найдем второе ребро остова, в котором будет уже 3 вершины, и т.д. пока все вершиеы графа не войдут в остов. При этом каждое вновь добавляемое в остов ребро не должно замыкать цикла (ребра, замыкающие циклы, должны пропускаться, какой бы малый вес они не имели). 

Этот алгорим может быть реализован с использованием приоритетной очереди - минимальной кучи.

Сначала в эту проритетную очередь помещают сразу **все** вершины, и одной из них (например, первой) приписывают нулевой приоритет, а всем остальным - бесконечно большое значение приоритета, так что именно она будет извлечена из минимальной кучи первой.

Далее, на каждом шаге алгоритма (после добавления к остову очередного ребра) приоритеты вершин персчитываются. Каждый раз они назначаются равными наименьшему весу какого-либо ребра, соединяющего данную вершину с уже построенной частью остова. После чего из кучи извлекается очередная вершина ("ближайшая" к построенной части остова), и соответсвующее инцидентное ей наиболее "легкое" ребро добавляется в остов. 

Алгоритм завершается, когда куча станет пустой.

## Примеры задач, не решаемых жадным алгоритмом

- Задача коммивояжера.

- Задача о рюкзаке (https://www.youtube.com/watch?v=HtrgxH3feME).

Перечисленные задачи относятся к так называемому классу `NP`-полных (говорят еще `NP`-трудных) задач. Этот класс характеризуется тем, что, во-первых, для задач этого класса пока неизвестны алгоритмы решения полиномиальной сложности (все известные алгоритмы имеют экспоненциальную или факториальную оценку сложности).
Во-вторых, если хотя бы для одной из задач этого класса будет найден алгоритм с полиномиальной оценкой сложности, то это будет означать также существование алгоритмов полиномиальной сложности для всех остальных задач этого класса. Однако обычно все специалисты соглашаются с (пока недоказанной и не опровергнутой) гипотезой о том, что класс алгоритмов полиномиальной сложности (класс P) и класс NP не совпадают (и, следовательно, не пересекаются). 